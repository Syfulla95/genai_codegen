{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import DoubleType, StringType, IntegerType\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Load data from Unity Catalog tables\ntry:\n    hospital_stats_df = spark.table(\"catalog.db.hospital_stats_north_america\")\n    sales_assignments_df = spark.table(\"catalog.db.hospital_sales_assignments\")\n    employment_details_df = spark.table(\"catalog.db.sales_associates_employment_details\")\n    compensation_guidelines_df = spark.table(\"catalog.db.compensation_guidelines\")\n    logistics_channels_df = spark.table(\"catalog.db.logistics_channels\")\n    growth_opportunities_df = spark.table(\"catalog.db.growth_opportunities\")\n    company_goals_df = spark.table(\"catalog.db.company_goals\")\n    historical_sales_df = spark.table(\"catalog.db.historical_sales\")\n    third_party_sales_trends_df = spark.table(\"catalog.db.third_party_sales_trends\")\nexcept Exception as e:\n    logger.error(f\"Error loading data from Unity Catalog: {e}\")\n    raise\n\n# Transformation logic\ntry:\n    # Join hospital statistics with sales assignments\n    hospital_sales_df = hospital_stats_df.join(\n        sales_assignments_df,\n        on=[\"Hospital_ID\", \"Hospital_Name\"],\n        how=\"inner\"\n    )\n\n    # Join employment details with compensation guidelines\n    employment_compensation_df = employment_details_df.join(\n        compensation_guidelines_df,\n        on=\"Associate_ID\",\n        how=\"inner\"\n    )\n\n    # Calculate total compensation\n    employment_compensation_df = employment_compensation_df.withColumn(\n        \"Compensation\",\n        F.col(\"Base_Salary\") + (F.col(\"Commission_Percentage\") / 100 * F.col(\"Base_Salary\")) + F.col(\"Bonus\")\n    )\n\n    # Select relevant fields\n    selected_employment_df = employment_compensation_df.select(\n        \"Associate_ID\", \"Associate_Name\", \"Compensation\", \"Region\", \"Employment_Type\", \"Years_of_Experience\", \"Department\"\n    )\n\n    # Join logistics channels with growth opportunities\n    logistics_growth_df = logistics_channels_df.join(\n        growth_opportunities_df,\n        on=[\"Channel_ID\", \"Channel_Type\", \"Hospital_ID\"],\n        how=\"inner\"\n    )\n\n    # Join compensation data with channel growth data\n    compensation_growth_df = selected_employment_df.join(\n        logistics_growth_df,\n        on=\"Hospital_ID\",\n        how=\"inner\"\n    )\n\n    # Select fields for further processing\n    selected_growth_df = compensation_growth_df.select(\n        \"Hospital_ID\", \"Channel_Type\", \"Growth_Opportunities\", \"Projected_Growth_Rate\"\n    )\n\n    # Join selected data with company goals\n    growth_goals_df = selected_growth_df.join(\n        company_goals_df,\n        on=[\"Hospital_ID\", \"Channel_Type\"],\n        how=\"inner\"\n    )\n\n    # Ensure unique records\n    unique_growth_goals_df = growth_goals_df.dropDuplicates([\"Hospital_ID\", \"Channel_Type\", \"Projected_Growth_Rate\", \"Investment_Planned\"])\n\n    # Join historical sales with third-party sales trends\n    sales_trends_df = historical_sales_df.join(\n        third_party_sales_trends_df,\n        on=\"Channel_Type\",\n        how=\"inner\"\n    )\n\n    # Ensure unique sales records\n    unique_sales_trends_df = sales_trends_df.dropDuplicates([\"Year\", \"Channel_Type\", \"Sales_Revenue\"])\n\n    # Combine unique sales data with growth data\n    combined_sales_growth_df = unique_sales_trends_df.join(\n        unique_growth_goals_df,\n        on=[\"Hospital_ID\", \"Channel_ID\", \"Channel_Type\"],\n        how=\"inner\"\n    )\n\n    # Generate rows for target years\n    target_years_df = combined_sales_growth_df.withColumn(\n        \"Target Year\",\n        F.expr(\"sequence(2023, 2026)\")\n    ).selectExpr(\"explode(`Target Year`) as `Target Year`\", \"*\")\n\n    # Calculate projected sales growth rate\n    target_years_df = target_years_df.withColumn(\n        \"projected_sales_growth_rate\",\n        F.when(F.col(\"Target Year\") == 2024, F.col(\"Projected_Growth_Rate\") + (F.col(\"Projected_Growth_Rate\") / 100))\n        .when(F.col(\"Target Year\") == 2025, (F.col(\"Projected_Growth_Rate\") + (F.col(\"Projected_Growth_Rate\") / 100)) + (F.col(\"Projected_Growth_Rate\") / 100))\n        .when(F.col(\"Target Year\") == 2026, ((F.col(\"Projected_Growth_Rate\") + (F.col(\"Projected_Growth_Rate\") / 100)) + (F.col(\"Projected_Growth_Rate\") / 100)) + (F.col(\"Projected_Growth_Rate\") / 100))\n        .otherwise(F.col(\"Projected_Growth_Rate\"))\n    )\n\n    # Calculate projected investments\n    target_years_df = target_years_df.withColumn(\n        \"projected_investments\",\n        F.when(F.col(\"Target Year\") == 2024, F.col(\"Investment_Planned\") * (F.col(\"projected_sales_growth_rate\") / 100))\n        .when(F.col(\"Target Year\") == 2025, F.col(\"Investment_Planned\") * (1 + F.col(\"projected_sales_growth_rate\") / 100))\n        .when(F.col(\"Target Year\") == 2026, F.col(\"Investment_Planned\") * (1 + F.col(\"projected_sales_growth_rate\") / 100))\n        .otherwise(F.col(\"Investment_Planned\"))\n    )\n\n    # Calculate projected revenue\n    target_years_df = target_years_df.withColumn(\n        \"Projected Revenue\",\n        F.when(F.col(\"Target Year\") == 2024, F.col(\"Sales_Revenue\") * (F.col(\"projected_sales_growth_rate\") / 100))\n        .when(F.col(\"Target Year\") == 2025, F.col(\"Sales_Revenue\") * (1 + F.col(\"projected_sales_growth_rate\") / 100))\n        .when(F.col(\"Target Year\") == 2026, F.col(\"Sales_Revenue\") * (1 + F.col(\"projected_sales_growth_rate\") / 100))\n        .otherwise(F.col(\"Sales_Revenue\"))\n    )\n\n    # Filter records based on target year\n    filtered_df = target_years_df.filter(F.col(\"Target Year\") > 2023)\n\n    # Select fields for final output\n    final_output_df = filtered_df.select(\n        \"Channel_Type\", \"Hospital_ID\", \"Market_Trend\", \"Political_Impact\", \"Economic_Impact\", \"Target Year\",\n        \"projected_sales_growth_rate\", \"projected_investments\", \"Projected Revenue\"\n    )\n\n    # Sort records by target year\n    sorted_output_df = final_output_df.orderBy(\"Target Year\")\n\nexcept Exception as e:\n    logger.error(f\"Error during transformation: {e}\")\n    raise\n\n# Output handling\ntry:\n    # Drop existing table if necessary\n    spark.sql(\"DROP TABLE IF EXISTS catalog.db.sales_prediction_output\")\n\n    # Write the processed data to Unity Catalog table using Delta format\n    sorted_output_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.db.sales_prediction_output\")\nexcept Exception as e:\n    logger.error(f\"Error writing data to Unity Catalog: {e}\")\n    raise\n\nlogger.info(\"ETL process completed successfully.\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}