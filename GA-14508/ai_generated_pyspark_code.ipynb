{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"\n",
                "\\nimport logging\\nfrom pyspark.sql import functions as F\\nfrom pyspark.sql.types import IntegerType\\nfrom datetime import datetime\\n\\n# Configure logging\\nlogging.basicConfig(level=logging.INFO)\\nlogger = logging.getLogger(__name__)\\n\\ntry:\\n    # Load data from Unity Catalog tables\\n    policy_df = spark.table(\\\"genai_demo.jnj.policy\\\")\\n    claims_df = spark.table(\\\"genai_demo.jnj.claims\\\")\\n    demographics_df = spark.table(\\\"genai_demo.jnj.demographics\\\")\\n    scores_df = spark.table(\\\"genai_demo.jnj.scores\\\")\\n    aiml_insights_df = spark.table(\\\"genai_demo.jnj.aiml_insights\\\")\\n\\n    # Select necessary fields\\n    demographics_df = demographics_df.select(\\\"Customer_ID\\\", \\\"Customer_Name\\\", \\\"Email\\\", \\\"Phone_Number\\\", \\\"Address\\\", \\\"City\\\", \\\"State\\\", \\\"Postal_Code\\\", \\\"Date_of_Birth\\\", \\\"Gender\\\", \\\"Marital_Status\\\", \\\"Occupation\\\", \\\"Income_Level\\\", \\\"Customer_Segment\\\")\\n    claims_df = claims_df.select(\\\"Claim_ID\\\", \\\"Policy_ID\\\", \\\"Claim_Date\\\", \\\"Claim_Type\\\", \\\"Claim_Status\\\", \\\"Claim_Amount\\\", \\\"Claim_Payout\\\")\\n    policy_df = policy_df.select(\\\"Policy_ID\\\", \\\"Customer_ID\\\", \\\"Policy_Type\\\", \\\"Policy_Status\\\", \\\"Policy_Start_Date\\\", \\\"Policy_End_Date\\\", \\\"Policy_Term\\\", \\\"Policy_Premium\\\", \\\"Total_Premium_Paid\\\", \\\"Renewal_Status\\\", \\\"Policy_Addons\\\")\\n    scores_df = scores_df.select(\\\"Customer_ID\\\", \\\"Credit_Score\\\", \\\"Fraud_Score\\\", \\\"Customer_Risk_Score\\\")\\n    aiml_insights_df = aiml_insights_df.select(\\\"Customer_ID\\\", \\\"Churn_Probability\\\", \\\"Next_Best_Offer\\\", \\\"Claims_Fraud_Probability\\\", \\\"Revenue_Potential\\\")\\n\\n    # Join demographics and policy data on Customer_ID\\n    customer_policy_df = demographics_df.join(policy_df, \\\"Customer_ID\\\", \\\"inner\\\")\\n\\n    # Join the result with claims data on Policy_ID\\n    customer_policy_claims_df = customer_policy_df.join(claims_df, \\\"Policy_ID\\\", \\\"inner\\\")\\n\\n    # Aggregate data\\n    summary_df = customer_policy_claims_df.groupBy(\\\"Customer_ID\\\").agg(\\n        F.count(\\\"Claim_ID\\\").alias(\\\"Total_Claims\\\"),\\n        F.max(\\\"Claim_Date\\\").alias(\\\"Recent_Claim_Date\\\"),\\n        F.avg(\\\"Claim_Amount\\\").alias(\\\"Average_Claim_Amount\\\"),\\n        F.countDistinct(\\\"Policy_ID\\\").alias(\\\"Policy_Count\\\")\\n    )\\n\\n    # Join summarized data with detailed customer data\\n    detailed_customer_df = customer_policy_claims_df.join(summary_df, \\\"Customer_ID\\\", \\\"inner\\\")\\n\\n    # Custom Calculations\\n    detailed_customer_df = detailed_customer_df.withColumn(\\\"Age\\\", F.floor(F.datediff(F.current_date(), F.to_date(\\\"Date_of_Birth\\\", \\\"yyyy-MM-dd\\\")) / 365.25))\\n    detailed_customer_df = detailed_customer_df.withColumn(\\\"Claim_To_Premium_Ratio\\\", F.when(F.col(\\\"Total_Premium_Paid\\\") != 0, F.col(\\\"Claim_Amount\\\") / F.col(\\\"Total_Premium_Paid\\\")).otherwise(0))\\n    detailed_customer_df = detailed_customer_df.withColumn(\\\"Claims_Per_Policy\\\", F.when(F.col(\\\"Policy_Count\\\") != 0, F.col(\\\"Total_Claims\\\") / F.col(\\\"Policy_Count\\\")).otherwise(0))\\n    detailed_customer_df = detailed_customer_df.withColumn(\\\"Retention_Rate\\\", F.lit(0.85))\\n    detailed_customer_df = detailed_customer_df.withColumn(\\\"Cross_Sell_Opportunities\\\", F.lit(\\\"Multi-Policy Discount, Home Coverage Add-on\\\"))\\n    detailed_customer_df = detailed_customer_df.withColumn(\\\"Upsell_Potential\\\", F.lit(\\\"Premium Vehicle Coverage\\\"))\\n\\n    # Join with AI/ML insights and scores data\\n    final_df = detailed_customer_df.join(aiml_insights_df, \\\"Customer_ID\\\", \\\"inner\\\").join(scores_df, \\\"Customer_ID\\\", \\\"inner\\\")\\n    final_df.show(10)\\n\\n    # Write the final output to Unity Catalog table\\n    #spark.sql(\\\"DROP TABLE IF EXISTS genai_demo.jnj.final_customer_data\\\")\\n    #final_df.write.format(\\\"delta\\\").mode(\\\"overwrite\\\").saveAsTable(\\\"genai_demo.jnj.final_customer_data\\\")\\n\\n    logger.info(\\\"Data processing and migration completed successfully.\\\")\\n\\nexcept Exception as e:\\n    logger.error(f\\\"An error occurred during data processing: {e}\\\")\"\"\"\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}