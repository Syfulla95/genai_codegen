{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# COMMAND ----------\n# MAGIC %md\n# MAGIC # ETL Process for Sales Prediction\n# MAGIC This notebook performs an ETL process to load, transform, and save sales prediction data using PySpark and Databricks Unity Catalog.\n\n# COMMAND ----------\n# MAGIC\n",
                "# Import necessary libraries\nimport logging\nfrom pyspark.sql import functions as F\n\n# COMMAND ----------\n# MAGIC\n",
                "# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n# MAGIC\n",
                "try:\n    # Load data from Unity Catalog tables to ensure data consistency and leverage Databricks' optimized data access\n    logger.info(\"Loading data from Unity Catalog tables...\")\n    hospital_stats_df = spark.table(\"genai_demo.cardinal_health.hospital_stats_north_america\")\n    sales_assignments_df = spark.table(\"genai_demo.cardinal_health.hospital_sales_assignments\")\n    employment_details_df = spark.table(\"genai_demo.cardinal_health.sales_associates_employment_details\")\n    compensation_guidelines_df = spark.table(\"genai_demo.cardinal_health.compensation_guidelines\")\n    logistics_channels_df = spark.table(\"genai_demo.cardinal_health.logistics_channels\")\n    growth_opportunities_df = spark.table(\"genai_demo.cardinal_health.growth_opportunities\")\n    company_goals_df = spark.table(\"genai_demo.cardinal_health.company_goals\")\n    historical_sales_df = spark.table(\"genai_demo.cardinal_health.historical_sales\")\n    third_party_trends_df = spark.table(\"genai_demo.cardinal_health.third_party_sales_trends\")\n\n# COMMAND ----------\n# MAGIC\n",
                "# Perform joins to integrate datasets based on key identifiers for comprehensive data analysis\n    logger.info(\"Performing data integration...\")\n    hospital_sales_df = hospital_stats_df.join(\n        sales_assignments_df, [F.col(\"Hospital_ID\"), F.col(\"Hospital_Name\")], \"inner\"\n    )\n    employment_compensation_df = employment_details_df.join(\n        compensation_guidelines_df, F.col(\"Associate_ID\"), \"inner\"\n    )\n    consolidated_df = hospital_sales_df.join(\n        employment_compensation_df, [F.col(\"Associate_ID\"), F.col(\"Associate_Name\")], \"inner\"\n    )\n\n# COMMAND ----------\n# MAGIC\n",
                "# Apply custom calculations to derive meaningful insights for strategic planning\n    logger.info(\"Applying custom calculations...\")\n    base_salary = F.col(\"Base_Salary\")\n    commission = F.col(\"Commission_Percentage\") * base_salary\n    bonus = F.col(\"Bonus\")\n    consolidated_df = consolidated_df.withColumn(\"Compensation\", base_salary + commission + bonus)\n\n# COMMAND ----------\n# MAGIC\n",
                "# Join logistics channels with growth opportunities\n    logistics_growth_df = logistics_channels_df.join(\n        growth_opportunities_df, [F.col(\"Channel_ID\"), F.col(\"Channel_Type\"), F.col(\"Hospital_ID\")], \"inner\"\n    )\n\n# COMMAND ----------\n# MAGIC\n",
                "# Join compensation data with logistics and growth data\n    final_df = consolidated_df.join(\n        logistics_growth_df, F.col(\"Hospital_ID\"), \"inner\"\n    ).select(\n        F.col(\"Hospital_ID\"), F.col(\"Channel_Type\"), F.col(\"Growth_Opportunities\"), F.col(\"Projected_Growth_Rate\")\n    )\n\n# COMMAND ----------\n# MAGIC\n",
                "# Join with company goals\n    final_df = final_df.join(\n        company_goals_df, [F.col(\"Hospital_ID\"), F.col(\"Channel_Type\")], \"inner\"\n    ).select(\n        F.col(\"Hospital_ID\"), F.col(\"Channel_Type\"), F.col(\"Growth_Opportunities\"), F.col(\"Projected_Growth_Rate\"),\n        F.col(\"Year\"), F.col(\"Channel_ID\"), F.col(\"Growth_Target\"), F.col(\"Investment_Planned\")\n    )\n\n# COMMAND ----------\n# MAGIC\n",
                "# Filter and sort data to focus on future projections and facilitate decision-making\n    logger.info(\"Filtering and sorting data...\")\n    filtered_df = final_df.filter(F.col(\"Year\") > 2023)\n    sorted_df = filtered_df.orderBy(\"Year\")\n\n# COMMAND ----------\n# MAGIC\n",
                "# Write output to Unity Catalog table for centralized access and further analysis\n    logger.info(\"Writing output to Unity Catalog table...\")\n    spark.sql(\"DROP TABLE IF EXISTS genai_demo.cardinal_health.sales_prediction_output\")\n    sorted_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.cardinal_health.sales_prediction_output\")\n\n    logger.info(\"ETL process completed successfully.\")\n\nexcept Exception as e:\n    logger.error(f\"An error occurred during the ETL process: {e}\")\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}