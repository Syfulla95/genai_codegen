{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import StringType\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ntry:\n    # Load data from Unity Catalog tables\n    class1_df = spark.table(\"postgresql_catalog.sas.class1\")\n    class2_df = spark.table(\"postgresql_catalog.sas.class2\")\n\n    # Sort datasets by Name\n    class1_sorted_df = class1_df.orderBy(\"Name\")\n    class2_sorted_df = class2_df.orderBy(\"Name\")\n\n    # Merge datasets on Name (inner join)\n    merged_df = class1_sorted_df.join(class2_sorted_df, on=\"Name\", how=\"inner\")\n\n    # Calculate BMI\n    bmi_df = merged_df.withColumn(\"BMI\", (F.col(\"Weight\") / (F.col(\"Height\") ** 2)) * 703)\n\n    # Define BMI categories\n    def bmi_category(bmi):\n        if bmi < 18.5:\n            return \"Underweight\"\n        elif 18.5 <= bmi < 24.9:\n            return \"Normal\"\n        elif 25 <= bmi < 29.9:\n            return \"Overweight\"\n        else:\n            return \"Obese\"\n\n    # Register UDF for BMI classification\n    bmi_category_udf = F.udf(bmi_category, StringType())\n    classified_df = bmi_df.withColumn(\"BMI_Category\", bmi_category_udf(F.col(\"BMI\")))\n\n    # Generate summary statistics\n    summary_stats_df = classified_df.select(\n        F.mean(\"Age\").alias(\"Mean_Age\"),\n        F.stddev(\"Age\").alias(\"Std_Age\"),\n        F.min(\"Age\").alias(\"Min_Age\"),\n        F.max(\"Age\").alias(\"Max_Age\"),\n        F.mean(\"Height\").alias(\"Mean_Height\"),\n        F.stddev(\"Height\").alias(\"Std_Height\"),\n        F.min(\"Height\").alias(\"Min_Height\"),\n        F.max(\"Height\").alias(\"Max_Height\"),\n        F.mean(\"Weight\").alias(\"Mean_Weight\"),\n        F.stddev(\"Weight\").alias(\"Std_Weight\"),\n        F.min(\"Weight\").alias(\"Min_Weight\"),\n        F.max(\"Weight\").alias(\"Max_Weight\"),\n        F.mean(\"BMI\").alias(\"Mean_BMI\"),\n        F.stddev(\"BMI\").alias(\"Std_BMI\"),\n        F.min(\"BMI\").alias(\"Min_BMI\"),\n        F.max(\"BMI\").alias(\"Max_BMI\")\n    )\n\n    # Frequency distribution of BMI categories\n    freq_dist_df = classified_df.groupBy(\"BMI_Category\").count()\n\n    # Generate class report card\n    report_card_df = classified_df.select(\"Name\", \"Age\", \"Sex\", \"Height\", \"Weight\", \"Grade\", \"GPA\", \"BMI\", \"BMI_Category\")\n\n    # Write outputs to Unity Catalog tables\n    summary_stats_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"postgresql_catalog.sas.summary_statistics\")\n    freq_dist_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"postgresql_catalog.sas.bmi_frequency_distribution\")\n    report_card_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"postgresql_catalog.sas.class_report_card\")\n\n    logger.info(\"Data processing and migration completed successfully.\")\n\nexcept Exception as e:\n    logger.error(f\"An error occurred during the data processing: {e}\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}