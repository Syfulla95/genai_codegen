{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nimport psycopg2\nfrom pyspark.sql import functions as F\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ntry:\n    # Step 1: Load data from Unity Catalog source tables\n    logger.info(\"Loading data from Unity Catalog source tables\")\n    try:\n        source_df = spark.table(\"catalog.source_db.source_table\")\n        logger.info(\"Data loaded successfully from Unity Catalog source tables\")\n    except Exception as e:\n        logger.error(f\"Failed to load data from Unity Catalog source tables: {e}\")\n        raise\n\n    # Step 2: Connect to external PostgreSQL database and fetch data\n    try:\n        logger.info(\"Connecting to external PostgreSQL database\")\n        # Check if secrets exist before attempting to retrieve them\n        secret_keys = [\"pg_host\", \"pg_port\", \"pg_dbname\", \"pg_user\", \"pg_password\"]\n        secrets = {}\n        missing_secrets = []\n\n        for key in secret_keys:\n            try:\n                # Corrected: Ensure dbutils.secrets.get() is used correctly\n                secrets[key] = dbutils.secrets.get(scope=\"my_scope\", key=key)\n            except Exception as e:\n                logger.error(f\"Failed to retrieve secret for key '{key}': {e}\")\n                missing_secrets.append(key)\n\n        if missing_secrets:\n            raise ValueError(f\"Missing secrets for keys: {', '.join(missing_secrets)}\")\n\n        # Corrected: Ensure psycopg2 connection parameters are correctly passed\n        conn = psycopg2.connect(\n            host=secrets[\"pg_host\"],\n            port=int(secrets[\"pg_port\"]),  # Ensure port is an integer\n            dbname=secrets[\"pg_dbname\"],\n            user=secrets[\"pg_user\"],\n            password=secrets[\"pg_password\"]\n        )\n        cursor = conn.cursor()\n        cursor.execute(\"SELECT * FROM legacy_table\")\n        legacy_data = cursor.fetchall()\n        logger.info(\"Data fetched successfully from PostgreSQL database\")\n    except Exception as e:\n        logger.error(f\"Failed to connect to PostgreSQL database: {e}\")\n        raise\n\n    # Step 3: Transform data\n    try:\n        logger.info(\"Transforming data\")\n        # Example transformation: Join source_df with legacy_data\n        legacy_df = spark.createDataFrame(legacy_data, schema=[\"key\", \"column1\", \"column2\", \"column3\"])\n        transformed_df = source_df.join(legacy_df, source_df[\"key\"] == legacy_df[\"key\"], \"inner\")\n\n        # Additional transformations (e.g., aggregations, filtering)\n        transformed_df = transformed_df.filter(F.col(\"column1\") > 100)\n        transformed_df = transformed_df.groupBy(\"column2\").agg(F.sum(\"column3\").alias(\"total_column3\"))\n        logger.info(\"Data transformation completed successfully\")\n    except Exception as e:\n        logger.error(f\"Data transformation failed: {e}\")\n        raise\n\n    # Step 4: Write transformed data to Unity Catalog target tables\n    try:\n        logger.info(\"Writing transformed data to Unity Catalog target tables\")\n        target_catalog = \"catalog_name\"\n        target_schema = \"schema_name\"\n        target_table = \"table_name\"\n\n        # Ensure schema exists before creating table\n        spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {target_catalog}.{target_schema}\")\n        logger.info(f\"Schema {target_catalog}.{target_schema} ensured\")\n\n        # Write to Unity Catalog target table (overwrite mode handles table replacement)\n        transformed_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{target_catalog}.{target_schema}.{target_table}\")\n        logger.info(\"Data written successfully to Unity Catalog target tables\")\n    except Exception as e:\n        logger.error(f\"Failed to write data to Unity Catalog target tables: {e}\")\n        raise\n\nexcept Exception as e:\n    logger.error(f\"ETL process failed: {e}\")\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}