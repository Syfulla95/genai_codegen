{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nimport pandas as pd\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import StructType, StructField, StringType, FloatType, DateType, IntegerType\nimport psycopg2\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Define schema for the flat file\nflat_file_schema = StructType([\n    StructField(\"AverageRate\", FloatType(), True),\n    StructField(\"CurrencyID\", StringType(), True),\n    StructField(\"CurrencyDate\", DateType(), True),\n    StructField(\"EndOfDayRate\", FloatType(), True)\n])\n\n# Load data from the flat file source\ntry:\n    flat_file_path = \"/Volumes/genai_demo/ssis/ssis/SampleCurrencyData.txt\"\n    flat_file_df = spark.read.format(\"csv\") \\\n        .option(\"header\", \"true\") \\\n        .schema(flat_file_schema) \\\n        .load(flat_file_path)\n    logger.info(\"Successfully loaded data from flat file.\")\nexcept Exception as e:\n    logger.error(f\"Error loading flat file: {e}\")\n    raise\n\n# Load data from DimCurrency1 table in Unity Catalog\ntry:\n    dim_currency_df = spark.table(\"sqlserver_catalog.dbo.dimcurrency1\")\n    logger.info(\"Successfully loaded data from DimCurrency1 table.\")\nexcept Exception as e:\n    logger.error(f\"Error loading DimCurrency1 table: {e}\")\n    raise\n\n# Load data from DimDate1 table in Unity Catalog\ntry:\n    dim_date_df = spark.table(\"sqlserver_catalog.dbo.dimdate1\")\n    logger.info(\"Successfully loaded data from DimDate1 table.\")\nexcept Exception as e:\n    logger.error(f\"Error loading DimDate1 table: {e}\")\n    raise\n\n# Perform lookup transformation for Currency Key\ntry:\n    currency_lookup_df = flat_file_df.join(\n        dim_currency_df,\n        flat_file_df.CurrencyID == dim_currency_df.CurrencyAlternateKey,\n        \"inner\"\n    ).select(\n        flat_file_df.AverageRate,\n        flat_file_df.EndOfDayRate,\n        flat_file_df.CurrencyID,\n        flat_file_df.CurrencyDate,\n        dim_currency_df.CurrencyAlternateKey\n    )\n    logger.info(\"Successfully performed currency key lookup.\")\nexcept Exception as e:\n    logger.error(f\"Error in currency key lookup: {e}\")\n    raise\n\n# Perform lookup transformation for Date Key\ntry:\n    final_df = currency_lookup_df.join(\n        dim_date_df,\n        currency_lookup_df.CurrencyDate == dim_date_df.FullDateAlternateKey,\n        \"inner\"\n    ).select(\n        currency_lookup_df.AverageRate,\n        currency_lookup_df.EndOfDayRate,\n        currency_lookup_df.CurrencyID,\n        currency_lookup_df.CurrencyDate,\n        currency_lookup_df.CurrencyAlternateKey,\n        dim_date_df.FullDateAlternateKey,\n        dim_date_df.DateKey\n    )\n    logger.info(\"Successfully performed date key lookup.\")\nexcept Exception as e:\n    logger.error(f\"Error in date key lookup: {e}\")\n    raise\n\n# Write the transformed data to the target Unity Catalog table\ntry:\n    target_table = \"sqlserver_catalog.dbo.SampleOLEDBDestination\"\n    spark.sql(f\"DROP TABLE IF EXISTS {target_table}\")\n    final_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(target_table)\n    logger.info(\"Successfully wrote data to the target table.\")\nexcept Exception as e:\n    logger.error(f\"Error writing to target table: {e}\")\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}