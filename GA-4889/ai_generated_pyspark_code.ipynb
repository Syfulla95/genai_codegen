{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# COMMAND ----------\n# MAGIC %md\n# MAGIC # ETL Process for Insurance Data\n# MAGIC This notebook performs an ETL process on insurance data, including data ingestion, transformation, integration of AI/ML insights, and output to a Unity Catalog table.\n\n# COMMAND ----------\n# MAGIC\n",
                "# Import necessary libraries\nimport logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.sql.functions import lit, when, datediff, current_date\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n# MAGIC\n",
                "# Step 1: Data Ingestion\ndef load_data():\n    try:\n        logger.info(\"Loading CSV files into DataFrames\")\n        policy_df = spark.read.csv(\"tfs://dataeconomy-9k42/62457/uploads/62457/29aabe9d-c354-4176-8f98-2dd7a5fd7216/policy.csv\", header=True, inferSchema=True)\n        claims_df = spark.read.csv(\"tfs://dataeconomy-9k42/62457/uploads/62457/29aabe9d-c354-4176-8f98-2dd7a5fd7216/claims.csv\", header=True, inferSchema=True)\n        demographics_df = spark.read.csv(\"tfs://dataeconomy-9k42/62457/uploads/62457/29aabe9d-c354-4176-8f98-2dd7a5fd7216/demographics.csv\", header=True, inferSchema=True)\n        scores_df = spark.read.csv(\"tfs://dataeconomy-9k42/62457/uploads/62457/29aabe9d-c354-4176-8f98-2dd7a5fd7216/scores.csv\", header=True, inferSchema=True)\n        aiml_insights_df = spark.read.csv(\"tfs://dataeconomy-9k42/62457/uploads/62457/29aabe9d-c354-4176-8f98-2dd7a5fd7216/aiml_insights.csv\", header=True, inferSchema=True)\n        return policy_df, claims_df, demographics_df, scores_df, aiml_insights_df\n    except Exception as e:\n        logger.error(f\"Error loading CSV files: {e}\")\n        raise\n\npolicy_df, claims_df, demographics_df, scores_df, aiml_insights_df = load_data()\n\n# COMMAND ----------\n# MAGIC\n",
                "# Step 2: Data Transformation\ndef transform_data(demographics_df, policy_df, claims_df):\n    try:\n        logger.info(\"Applying transformations\")\n\n        # Join demographics and policy data\n        demo_policy_df = demographics_df.join(policy_df, F.col('Customer_ID') == F.col('customer_id'), \"inner\")\n\n        # Join with claims data\n        demo_policy_claims_df = demo_policy_df.join(claims_df, F.col('policy_id') == F.col('Policy_ID'), \"inner\")\n\n        # Aggregate claims data\n        summary_df = demo_policy_claims_df.groupBy(\"Customer_ID\").agg(\n            F.count(\"Claim_ID\").alias(\"Total_Claims\"),\n            F.count(\"policy_id\").alias(\"Policy_Count\"),\n            F.max(\"Claim_Date\").alias(\"Recent_Claim_Date\"),\n            F.avg(\"Claim_Amount\").alias(\"Average_Claim_Amount\")\n        )\n\n        # Calculate additional metrics\n        age_expr = (datediff(current_date(), F.col(\"Date_of_Birth\")) / 365).cast(IntegerType())\n        claim_to_premium_ratio_expr = when(F.col(\"total_premium_paid\") != 0, F.col(\"Claim_Amount\") / F.col(\"total_premium_paid\")).otherwise(0)\n        claims_per_policy_expr = when(F.col(\"Policy_Count\") != 0, F.col(\"Total_Claims\") / F.col(\"Policy_Count\")).otherwise(0)\n\n        final_df = summary_df.withColumn(\"Age\", age_expr) \\\n                             .withColumn(\"Claim_To_Premium_Ratio\", claim_to_premium_ratio_expr) \\\n                             .withColumn(\"Claims_Per_Policy\", claims_per_policy_expr) \\\n                             .withColumn(\"Retention_Rate\", lit(0.85)) \\\n                             .withColumn(\"Cross_Sell_Opportunities\", lit(\"Multi-Policy Discount, Home Coverage Add-on\")) \\\n                             .withColumn(\"Upsell_Potential\", lit(\"Premium Vehicle Coverage\"))\n\n        # Define schema contract\n        final_df = final_df.select(\n            \"Customer_ID\", \"Age\", \"Claim_To_Premium_Ratio\", \"Claims_Per_Policy\", \n            \"Retention_Rate\", \"Cross_Sell_Opportunities\", \"Upsell_Potential\"\n        )\n        return final_df\n    except Exception as e:\n        logger.error(f\"Error during data transformation: {e}\")\n        raise\n\nfinal_df = transform_data(demographics_df, policy_df, claims_df)\n\n# COMMAND ----------\n# MAGIC\n",
                "# Step 3: Integrate AI/ML Insights and Scores\ndef integrate_insights(final_df, aiml_insights_df, scores_df):\n    try:\n        logger.info(\"Integrating AI/ML insights and scores\")\n        customer_360_df = final_df.join(aiml_insights_df, \"Customer_ID\", \"inner\") \\\n                                  .join(scores_df, \"Customer_ID\", \"inner\")\n        return customer_360_df\n    except Exception as e:\n        logger.error(f\"Error integrating AI/ML insights and scores: {e}\")\n        raise\n\ncustomer_360_df = integrate_insights(final_df, aiml_insights_df, scores_df)\n\n# COMMAND ----------\n# MAGIC\n",
                "# Step 4: Output Data\ndef output_data(customer_360_df):\n    try:\n        logger.info(\"Writing output data to Unity Catalog table\")\n        # Drop existing table if necessary\n        spark.sql(\"DROP TABLE IF EXISTS catalog.target_db.customer_360\")\n\n        # Write to Unity Catalog target table\n        customer_360_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.target_db.customer_360\")\n    except Exception as e:\n        logger.error(f\"Error writing output data: {e}\")\n        raise\n\noutput_data(customer_360_df)\n\nlogger.info(\"ETL process completed successfully\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}