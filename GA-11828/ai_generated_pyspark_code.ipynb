{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nfrom pyspark.sql import functions as F\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ntry:\n    # Load data from Unity Catalog tables\n    orders_central_df = spark.table(\"genai_demo.citi.orders_central\")\n    orders_east_df = spark.table(\"genai_demo.citi.orders_east\")\n    orders_south_2015_df = spark.table(\"genai_demo.citi.orders_south_2015\")\n    orders_south_2016_df = spark.table(\"genai_demo.citi.orders_south_2016\")\n    orders_south_2017_df = spark.table(\"genai_demo.citi.orders_south_2017\")\n    orders_south_2018_df = spark.table(\"genai_demo.citi.orders_south_2018\")\n    orders_west_df = spark.table(\"genai_demo.citi.orders_west\")\n    quota_df = spark.table(\"genai_demo.citi.quota\")\n    returns_df = spark.table(\"genai_demo.citi.returns\")\n\n    # Fix Dates: Standardize date fields and column names\n    orders_central_df = orders_central_df.withColumn(\"Region\", F.lit(\"Central\")) \\\n        .withColumn(\"Order Date\", F.to_date(F.concat_ws(\"-\", F.col(\"Order Year\"), F.col(\"Order Month\"), F.col(\"Order Day\")), \"yyyy-MM-dd\")) \\\n        .withColumn(\"Ship Date\", F.to_date(F.concat_ws(\"-\", F.col(\"Ship Year\"), F.col(\"Ship Month\"), F.col(\"Ship Day\")), \"yyyy-MM-dd\")) \\\n        .drop(\"Order Year\", \"Order Month\", \"Order Day\", \"Ship Year\", \"Ship Month\", \"Ship Day\") \\\n        .withColumnRenamed(\"Discounts\", \"Discount\") \\\n        .withColumnRenamed(\"Product\", \"Product Name\")\n\n    # Remove Nulls: Exclude rows with null Order ID\n    orders_central_df = orders_central_df.filter(F.col(\"Order ID\").isNotNull())\n\n    # Fix Data Type: Ensure correct data types\n    orders_central_df = orders_central_df.withColumn(\"Discount\", F.col(\"Discount\").cast(\"string\")) \\\n        .withColumn(\"Sales\", F.regexp_replace(F.col(\"Sales\"), \"[^0-9.]\", \"\").cast(\"double\"))\n\n    # Rename States: Standardize state names to abbreviations\n    state_mapping = {\n        \"Arizona\": \"AZ\", \"California\": \"CA\", \"Colorado\": \"CO\", \"Idaho\": \"ID\",\n        \"Montana\": \"MT\", \"New Mexico\": \"NM\", \"Oregon\": \"OR\", \"Washington\": \"WA\", \"Utah\": \"UT\"\n    }\n    orders_central_df = orders_central_df.replace(state_mapping, subset=[\"State\"])\n\n    # Pivot Quotas: Unpivot quota data to create Year and Quota fields\n    quota_df = quota_df.selectExpr(\"Region\", \"stack(4, '2015', 2015, '2016', 2016, '2017', 2017, '2018', 2018) as (Year, Quota)\")\n\n    # Clean Notes/Approver: Split Notes into Return Notes and Approver, standardize names, and remove original Notes\n    returns_df = returns_df.withColumn(\"Return Notes\", F.trim(F.split(F.col(\"Notes\"), \"-\").getItem(0))) \\\n        .withColumn(\"Approver\", F.trim(F.split(F.col(\"Notes\"), \"-\").getItem(1))) \\\n        .drop(\"Notes\")\n\n    approver_mapping = {\n        \"M/ Gomez\": \"M Gomez\", \"M. Gomez\": \"M Gomez\", \"S Kelly\": \"S Kelly\", \"S. Kelly\": \"S Kelly\",\n        \"F Azad\": \"F Azad\", \"F. Azad\": \"F Azad\", \"L Smith\": \"L Smith\", \"L. Smith\": \"L Smith\",\n        \"G Lindsay\": \"G Lindsay\", \"G. Lindsay\": \"G Lindsay\", \"R Chen\": \"R Chen\", \"R. Chen\": \"R Chen\",\n        \"K Lawrence\": \"K Lawrence\", \"K. Lawrence\": \"K Lawrence\", \"L Jenkins\": \"L Jenkins\", \"L. Jenkins\": \"L Jenkins\",\n        \"R Duchesne\": \"R Duchesne\", \"R. Duchesne\": \"R Duchesne\"\n    }\n    returns_df = returns_df.replace(approver_mapping, subset=[\"Approver\"])\n\n    # All Orders: Union all order datasets into a single DataFrame\n    all_orders_df = orders_central_df.union(orders_east_df).union(orders_south_2015_df) \\\n        .union(orders_south_2016_df).union(orders_south_2017_df).union(orders_south_2018_df).union(orders_west_df)\n\n    # Orders + Returns: Join orders with returns data\n    orders_returns_df = all_orders_df.join(returns_df, [\"Order ID\", \"Product ID\"], \"right\") \\\n        .withColumn(\"Returned?\", F.when(F.col(\"Return Reason\").isNotNull(), \"Yes\").otherwise(\"No\")) \\\n        .withColumn(\"Days to Ship\", F.datediff(F.col(\"Ship Date\"), F.col(\"Order Date\"))) \\\n        .withColumn(\"Discount\", F.when(F.col(\"Discount\").isNull(), 0).otherwise(F.col(\"Discount\"))) \\\n        .withColumn(\"Year of Sale\", F.year(F.col(\"Order Date\"))) \\\n        .filter(~((F.col(\"Discount\") >= 17) & (F.col(\"Discount\") < 18)))\n\n    # Roll Up Sales: Aggregate sales data\n    rollup_sales_df = orders_returns_df.groupBy(\"Region\", \"Year of Sale\") \\\n        .agg(F.sum(\"Profit\").alias(\"Profit\"), F.sum(\"Sales\").alias(\"Sales\"), F.sum(\"Quantity\").alias(\"Quantity\"), F.avg(\"Discount\").alias(\"Discount\"))\n\n    # Quota + Orders: Join quota with aggregated sales data\n    quota_orders_df = quota_df.join(rollup_sales_df, (quota_df.Region == rollup_sales_df.Region) & (quota_df.Year == rollup_sales_df[\"Year of Sale\"]), \"inner\")\n\n    # Write to Unity Catalog target tables\n    spark.sql(\"DROP TABLE IF EXISTS genai_demo.citi.superstore_sales\")\n    orders_returns_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.citi.superstore_sales\")\n\n    spark.sql(\"DROP TABLE IF EXISTS genai_demo.citi.annual_regional_performance\")\n    quota_orders_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.citi.annual_regional_performance\")\n\n    logger.info(\"Data migration completed successfully.\")\n\nexcept Exception as e:\n    logger.error(f\"Error during data migration: {e}\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}