{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import IntegerType, StringType, DateType\nfrom datetime import datetime\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ntry:\n    # Load data from Unity Catalog tables\n    customers_df = spark.table(\"genai_demo.sas.customers\")\n    transactions_df = spark.table(\"genai_demo.sas.transactions\")\n\n    # Step 1: Filter valid transactions\n    valid_txns_df = transactions_df.filter((F.col(\"Sales\") > 0) & (F.col(\"Product\") != \"\"))\n\n    # Step 2: Calculate Effective Price\n    trans_step2_df = valid_txns_df.withColumn(\"EffectivePrice\", F.col(\"Sales\") * (1 - F.col(\"Discount\") / 100))\n\n    # Step 3: Calculate Total Value\n    trans_step3_df = trans_step2_df.withColumn(\"TotalValue\", F.col(\"EffectivePrice\") * F.col(\"Quantity\"))\n\n    # Step 4: Join with Customers\n    full_data_df = trans_step3_df.join(customers_df, \"CustomerID\", \"left\").select(\n        trans_step3_df[\"*\"], customers_df[\"Region\"], customers_df[\"JoinDate\"]\n    )\n\n    # Step 5: Calculate Tenure Days\n    trans_step5_df = full_data_df.withColumn(\n        \"TenureDays\", F.datediff(F.col(\"TransDate\"), F.col(\"JoinDate\"))\n    )\n\n    # Step 6: Assign Tenure Category\n    trans_step6_df = trans_step5_df.withColumn(\n        \"TenureCategory\",\n        F.when(F.col(\"TenureDays\") < 180, \"New\")\n        .when(F.col(\"TenureDays\") < 365, \"Medium\")\n        .otherwise(\"Loyal\")\n    )\n\n    # Step 7: Flag High Value Transactions\n    trans_step7_df = trans_step6_df.withColumn(\"HighValueFlag\", F.col(\"TotalValue\") > 2000)\n\n    # Step 8: Assign Product Group\n    trans_step8_df = trans_step7_df.withColumn(\n        \"ProductGroup\",\n        F.when(F.col(\"Product\").isin([\"A\", \"C\"]), \"Core\").otherwise(\"Non-Core\")\n    )\n\n    # Final Data Preparation\n    final_data_df = trans_step8_df\n\n    # Step 9: Sort by ProductGroup\n    sorted_final_data_df = final_data_df.orderBy(\"ProductGroup\")\n\n    # Step 10: Standardize TotalValue\n    standardized_df = sorted_final_data_df.groupBy(\"ProductGroup\").agg(\n        F.mean(\"TotalValue\").alias(\"mean_TotalValue\"),\n        F.stddev(\"TotalValue\").alias(\"stddev_TotalValue\")\n    ).join(sorted_final_data_df, \"ProductGroup\").withColumn(\n        \"StandardizedTotalValue\",\n        (F.col(\"TotalValue\") - F.col(\"mean_TotalValue\")) / F.col(\"stddev_TotalValue\")\n    )\n\n    # Step 11: Outlier Detection\n    enhanced_final_data_df = standardized_df.withColumn(\n        \"OutlierFlag\", F.when(F.abs(F.col(\"StandardizedTotalValue\")) > 2, 1).otherwise(0)\n    )\n\n    # Write the final output to Unity Catalog\n    spark.sql(\"DROP TABLE IF EXISTS genai_demo.sas.enhanced_final_data\")\n    enhanced_final_data_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.sas.enhanced_final_data\")\n\n    # Additional Analysis Outputs\n    # Summary Statistics\n    summary_stats_df = enhanced_final_data_df.groupBy(\"Region\", \"ProductGroup\").agg(\n        F.mean(\"TotalValue\").alias(\"mean_TotalValue\"),\n        F.sum(\"TotalValue\").alias(\"sum_TotalValue\"),\n        F.mean(\"Quantity\").alias(\"mean_Quantity\"),\n        F.sum(\"Quantity\").alias(\"sum_Quantity\"),\n        F.mean(\"Sales\").alias(\"mean_Sales\"),\n        F.sum(\"Sales\").alias(\"sum_Sales\")\n    )\n    summary_stats_df.show()\n\n    # Frequency Analysis\n    freq_analysis_df = enhanced_final_data_df.groupBy(\"TenureCategory\", \"Region\").count()\n    freq_analysis_df.show()\n\n    # Correlation Analysis\n    correlation_df = enhanced_final_data_df.select(\"Sales\", \"Discount\", \"Quantity\", \"TotalValue\").corr()\n    logger.info(\"Correlation Analysis: %s\", correlation_df)\n\n    # Outlier Summary\n    outlier_summary_df = enhanced_final_data_df.groupBy(\"OutlierFlag\").agg(\n        F.mean(\"Sales\").alias(\"mean_Sales\"),\n        F.stddev(\"Sales\").alias(\"stddev_Sales\"),\n        F.mean(\"TotalValue\").alias(\"mean_TotalValue\"),\n        F.stddev(\"TotalValue\").alias(\"stddev_TotalValue\"),\n        F.mean(\"Quantity\").alias(\"mean_Quantity\"),\n        F.stddev(\"Quantity\").alias(\"stddev_Quantity\")\n    )\n    outlier_summary_df.show()\n\nexcept Exception as e:\n    logger.error(\"An error occurred during the ETL process: %s\", str(e))\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}