{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# COMMAND ----------\n# %md\n# # ETL Process for Sales Prediction\n# This notebook performs an ETL process to load, integrate, and transform data for sales prediction using PySpark.\n\n# COMMAND ----------\n#\n",
                "# Import necessary libraries\nimport logging\nfrom pyspark.sql import functions as F\n\n# COMMAND ----------\n#\n",
                "# Initialize logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n#\n",
                "# Function to load data from Unity Catalog tables\ndef load_data():\n    logger.info(\"Loading data from Unity Catalog tables...\")\n    hospital_stats_df = spark.table(\"genai_demo.cardinal_health.hospital_stats_north_america\")\n    sales_assignments_df = spark.table(\"genai_demo.cardinal_health.hospital_sales_assignments\")\n    employment_details_df = spark.table(\"genai_demo.cardinal_health.sales_associates_employment_details\")\n    compensation_guidelines_df = spark.table(\"genai_demo.cardinal_health.compensation_guidelines\")\n    logistics_channels_df = spark.table(\"genai_demo.cardinal_health.logistics_channels\")\n    growth_opportunities_df = spark.table(\"genai_demo.cardinal_health.growth_opportunities\")\n    company_goals_df = spark.table(\"genai_demo.cardinal_health.company_goals\")\n    historical_sales_df = spark.table(\"genai_demo.cardinal_health.historical_sales\")\n    third_party_trends_df = spark.table(\"genai_demo.cardinal_health.third_party_sales_trends\")\n    return (hospital_stats_df, sales_assignments_df, employment_details_df, \n            compensation_guidelines_df, logistics_channels_df, growth_opportunities_df, \n            company_goals_df, historical_sales_df, third_party_trends_df)\n\n# COMMAND ----------\n#\n",
                "# Function to perform data integration\ndef integrate_data(hospital_stats_df, sales_assignments_df, employment_details_df, compensation_guidelines_df):\n    logger.info(\"Performing data integration...\")\n    hospital_sales_df = hospital_stats_df.join(sales_assignments_df, [\"Hospital_ID\", \"Hospital_Name\"], \"inner\")\n    employment_compensation_df = employment_details_df.join(compensation_guidelines_df, \"Associate_ID\", \"inner\")\n    consolidated_df = hospital_sales_df.join(employment_compensation_df, [\"Associate_ID\", \"Hospital_ID\"], \"inner\")\n    return consolidated_df\n\n# COMMAND ----------\n#\n",
                "# Function to calculate total compensation\ndef calculate_compensation(consolidated_df):\n    logger.info(\"Calculating total compensation for associates...\")\n    consolidated_df = consolidated_df.withColumn(\"Compensation\", \n        F.col(\"Base_Salary\") + (F.col(\"Commission_Percentage\") * F.col(\"Base_Salary\")) + F.col(\"Bonus\"))\n    return consolidated_df\n\n# COMMAND ----------\n#\n",
                "# Function to filter and sort data\ndef filter_and_sort_data(consolidated_df):\n    logger.info(\"Filtering and sorting data...\")\n    target_year_condition = F.col(\"Target Year\") > 2023\n    filtered_df = consolidated_df.filter(target_year_condition).orderBy(\"Target Year\")\n    return filtered_df\n\n# COMMAND ----------\n#\n",
                "# Function to generate final output\ndef generate_output(filtered_df):\n    logger.info(\"Generating final output for sales predictions...\")\n    sales_prediction_output_df = filtered_df.select(\n        F.col(\"Channel_Type\").alias(\"Channel_Type\"),\n        F.col(\"Hospital_ID\").alias(\"Hospital_ID\"),\n        F.col(\"Market_Trend\").alias(\"Market_Trend\"),\n        F.col(\"Political_Impact\").alias(\"Political_Impact\"),\n        F.col(\"Economic_Impact\").alias(\"Economic_Impact\"),\n        F.col(\"Target Year\").alias(\"Target_Year\"),\n        F.col(\"projected_sales_growth_rate\").alias(\"Projected_Sales_Growth_Rate\"),\n        F.col(\"projected_investments\").alias(\"Projected_Investments\"),\n        F.col(\"Projected Revenue\").alias(\"Projected_Revenue\")\n    )\n    return sales_prediction_output_df\n\n# COMMAND ----------\n#\n",
                "# Function to write output to Unity Catalog\ndef write_output(sales_prediction_output_df):\n    logger.info(\"Writing output to Unity Catalog target table...\")\n    spark.sql(\"DROP TABLE IF EXISTS genai_demo.cardinal_health.sales_prediction_output\")\n    sales_prediction_output_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.cardinal_health.sales_prediction_output\")\n\n# COMMAND ----------\n#\n",
                "# Main ETL process\ntry:\n    # Load data\n    data = load_data()\n    \n    # Integrate data\n    consolidated_df = integrate_data(*data[:4])\n    \n    # Calculate compensation\n    consolidated_df = calculate_compensation(consolidated_df)\n    \n    # Filter and sort data\n    filtered_df = filter_and_sort_data(consolidated_df)\n    \n    # Generate output\n    sales_prediction_output_df = generate_output(filtered_df)\n    \n    # Write output\n    write_output(sales_prediction_output_df)\n    \n    logger.info(\"ETL process completed successfully.\")\n\nexcept Exception as e:\n    logger.error(f\"An error occurred during the ETL process: {e}\")\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}