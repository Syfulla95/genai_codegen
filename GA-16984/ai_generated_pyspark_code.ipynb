{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import StringType\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Function to load data from MySQL\ndef load_mysql_data(query, connection_details):\n    try:\n        import psycopg2  # Import inside the function to avoid unnecessary import if not used\n        conn = psycopg2.connect(**connection_details)\n        cursor = conn.cursor()\n        cursor.execute(query)\n        data = cursor.fetchall()\n        columns = [desc[0] for desc in cursor.description]\n        cursor.close()\n        conn.close()\n        return spark.createDataFrame(data, schema=columns)\n    except Exception as e:\n        logger.error(f\"Error loading data from MySQL: {e}\")\n        raise\n\n# Load data from Unity Catalog tables\ndef load_unity_catalog_table(table_name):\n    try:\n        df = spark.table(table_name)\n        logger.info(f\"Loaded {df.count()} records from {table_name}\")\n        return df\n    except Exception as e:\n        logger.error(f\"Error loading data from Unity Catalog table {table_name}: {e}\")\n        raise\n\n# Load data from external files\ndef load_external_file(file_path):\n    try:\n        df = spark.read.format(\"yxdb\").load(file_path)\n        logger.info(f\"Loaded {df.count()} records from {file_path}\")\n        return df\n    except Exception as e:\n        logger.error(f\"Error loading data from file {file_path}: {e}\")\n        raise\n\n# Transformation logic\ndef apply_transformations(df):\n    try:\n        # Example transformation: Trim and clean specific fields\n        df = df.withColumn(\"_BusinessUnitCode\", F.trim(F.col(\"BusinessUnitCode\")))\n        df = df.withColumn(\"_FMRCCode\", F.trim(F.col(\"FMRCCode\")))\n        # Add more transformations as needed\n        logger.info(f\"Applied transformations, resulting in {df.count()} records\")\n        return df\n    except Exception as e:\n        logger.error(f\"Error applying transformations: {e}\")\n        raise\n\n# Join operation\ndef perform_join(df1, df2, join_condition):\n    try:\n        joined_df = df1.join(df2, join_condition, \"inner\")\n        logger.info(f\"Performed join, resulting in {joined_df.count()} records\")\n        return joined_df\n    except Exception as e:\n        logger.error(f\"Error performing join: {e}\")\n        raise\n\n# Write data to Unity Catalog table\ndef write_to_unity_catalog(df, catalog, schema, table):\n    try:\n        spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema}\")\n        df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{catalog}.{schema}.{table}\")\n        logger.info(f\"Written data to {catalog}.{schema}.{table}\")\n    except Exception as e:\n        logger.error(f\"Error writing data to Unity Catalog table {catalog}.{schema}.{table}: {e}\")\n        raise\n\n# Main ETL workflow\ndef etl_workflow():\n    try:\n        # Load data from MySQL\n        try:\n            mysql_connection_details = {\n                \"host\": dbutils.secrets.get(\"mysql\", \"host\"),\n                \"database\": dbutils.secrets.get(\"mysql\", \"database\"),\n                \"user\": dbutils.secrets.get(\"mysql\", \"user\"),\n                \"password\": dbutils.secrets.get(\"mysql\", \"password\")\n            }\n        except Exception as e:\n            logger.error(f\"Error retrieving MySQL connection details from Databricks secrets: {e}\")\n            raise\n\n        mysql_df = load_mysql_data(\"SELECT * FROM pjotr_prod\", mysql_connection_details)\n\n        # Load data from Unity Catalog tables\n        text_input_df = load_unity_catalog_table(\"catalog.source_db.text_input\")\n        bseg_df = load_unity_catalog_table(\"catalog.source_db.c04_bseg\")\n        ekpo_df = load_unity_catalog_table(\"catalog.source_db.c04_ekpo\")\n        pes_df = load_unity_catalog_table(\"catalog.source_db.pjotr_in_pes\")\n        ivl_data_df = load_unity_catalog_table(\"catalog.source_db.c19_ivl_data\")\n        mysql_editable_df = load_unity_catalog_table(\"catalog.source_db.mysql_editable\")\n        pjotr_df = load_unity_catalog_table(\"catalog.source_db.pjotr\")\n        pes_prep_df = load_unity_catalog_table(\"catalog.source_db.pes_prep\")\n\n        # Apply transformations\n        transformed_df = apply_transformations(mysql_df)\n\n        # Perform join operations\n        joined_df = perform_join(transformed_df, pes_df, transformed_df[\"_LECode\"] == pes_df[\"LECode\"])\n\n        # Write output to Unity Catalog tables\n        write_to_unity_catalog(joined_df, \"catalog_name\", \"schema_name\", \"c03_pjotr\")\n        write_to_unity_catalog(joined_df, \"catalog_name\", \"schema_name\", \"c03_pjotr_midway\")\n        write_to_unity_catalog(joined_df, \"catalog_name\", \"schema_name\", \"c03_unmapped_to_pjotr\")\n        write_to_unity_catalog(joined_df, \"catalog_name\", \"schema_name\", \"c03_pjotr_final\")\n        write_to_unity_catalog(joined_df, \"catalog_name\", \"schema_name\", \"pjotr_in_pes\")\n\n    except Exception as e:\n        logger.error(f\"Error in ETL workflow: {e}\")\n        raise\n\n# Execute the ETL workflow\netl_workflow()\n\n# Corrected Code Explanation:\n# 1. The error was due to missing secrets in the Databricks environment. Ensure that the secrets are correctly set up in Databricks.\n# 2. Added error handling for secret retrieval to log specific errors related to missing secrets.\n# 3. The rest of the code remains unchanged as it was successfully reviewed and approved.\n# 4. Ensure that the Unity Catalog tables and schemas exist before attempting to load or write data.\n# 5. Added logging to capture successful operations and errors for better observability.\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}