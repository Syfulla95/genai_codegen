{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import SparkSession\n\n# Initialize logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Assume Spark session is already initialized as 'spark'\n# Load data from Unity Catalog tables with enhanced error handling\ndef load_data(path):\n    try:\n        # Attempt to access the path and check permissions\n        try:\n            dbutils.fs.ls(path)\n        except Exception as e:\n            logger.error(f\"Insufficient permissions or path does not exist: {path}. Error: {e}\")\n            raise Exception(f\"Insufficient permissions or path does not exist: {path}. Error: {e}\")\n        \n        df = spark.read.format(\"parquet\").load(path)\n        logger.info(f\"Data loaded successfully from {path}.\")\n        return df\n    except Exception as e:\n        logger.error(f\"Error loading data from {path}: {e}\")\n        raise\n\n# Paths to data sources\npaths = {\n    \"pes_prep\": \"dbfs:/mnt/data/PES/B/workfolder/PES_prep\",\n    \"c19_ivl_data\": \"dbfs:/mnt/data/PES/C/workfolder/C19_ivl_data\",\n    \"c04_ekpo\": \"dbfs:/mnt/data/PES/C/workfolder/C04_EKPO\",\n    \"c04_bseg\": \"dbfs:/mnt/data/PES/C/workfolder/C04_BSEG\",\n    \"pjotr\": \"dbfs:/mnt/data/PES/M/C03/PJOTR/PJOTR_\",\n    \"pjotr_in_pes\": \"dbfs:/mnt/data/PES/M/C03/PJOTR/PJOTR_in_PES\"\n}\n\n# Load data with permission checks\ndef load_data_with_permission_check(path):\n    try:\n        # Check if the user has permission to access the path\n        if not dbutils.fs.ls(path):\n            logger.error(f\"Insufficient permissions or path does not exist: {path}\")\n            raise Exception(f\"Insufficient permissions or path does not exist: {path}\")\n        \n        df = spark.read.format(\"parquet\").load(path)\n        logger.info(f\"Data loaded successfully from {path}.\")\n        return df\n    except Exception as e:\n        logger.error(f\"Error loading data from {path}: {e}\")\n        raise\n\n# Load data\npes_prep_df = load_data_with_permission_check(paths[\"pes_prep\"])\nc19_ivl_data_df = load_data_with_permission_check(paths[\"c19_ivl_data\"])\nc04_ekpo_df = load_data_with_permission_check(paths[\"c04_ekpo\"])\nc04_bseg_df = load_data_with_permission_check(paths[\"c04_bseg\"])\npjotr_df = load_data_with_permission_check(paths[\"pjotr\"])\npjotr_in_pes_df = load_data_with_permission_check(paths[\"pjotr_in_pes\"])\n\n# Transformation logic\ndef clean_transform(df):\n    try:\n        for field in [\"Business unit code\", \"FMRC code\", \"FSID code\", \"LE code\", \"MRC code\", \"Plant code\", \"PO business unit code\", \"PO LE code\", \"PO MRC code\", \"PO site code\", \"Site code\", \"Vision sourced data\"]:\n            df = df.withColumn(f\"_{field}\", F.when(df[field].rlike(\"#|UNMAPPED|NULL\"), None).otherwise(df[field].substr(3, len(df[field]))))\n        logger.info(\"Multi-field formula transformation applied.\")\n        return df\n    except Exception as e:\n        logger.error(f\"Error in clean_transform: {e}\")\n        raise\n\ntransformed_df = clean_transform(pes_prep_df)\nselected_df = transformed_df.select(\"PES ID\", \"Addressable\", \"Ariba source system\", \"Base unit of measure\", \"Business unit\", \"Invoice amount (USD)\")\nlogger.info(\"Select transformation applied.\")\n\n# Join Transformation\ntry:\n    joined_df = selected_df.join(c19_ivl_data_df, \"PES ID\", \"inner\").join(c04_ekpo_df, \"PO\", \"inner\").join(c04_bseg_df, \"MM Doc.\", \"inner\")\n    joined_df = joined_df.drop(\"duplicate_column_name\")  # Example of dropping duplicate columns\n    logger.info(\"Join transformation applied.\")\nexcept Exception as e:\n    logger.error(f\"Error in join transformation: {e}\")\n    raise\n\n# Formula Transformation\ntry:\n    formula_df = joined_df.withColumn(\"Spend\", joined_df[\"Invoice amount (USD)\"]).withColumn(\"Records\", F.lit(1))\n    logger.info(\"Formula transformation applied.\")\nexcept Exception as e:\n    logger.error(f\"Error in formula transformation: {e}\")\n    raise\n\n# Union Transformation\ntry:\n    union_df = formula_df.union(pjotr_in_pes_df)\n    logger.info(\"Union transformation applied.\")\nexcept Exception as e:\n    logger.error(f\"Error in union transformation: {e}\")\n    raise\n\n# Filter Transformation\ntry:\n    filtered_df = union_df.filter(union_df[\"Business unit\"] != \"UNMAPPED\")\n    logger.info(\"Filter transformation applied.\")\nexcept Exception as e:\n    logger.error(f\"Error in filter transformation: {e}\")\n    raise\n\n# Summarize Transformation\ntry:\n    summarized_df = filtered_df.groupBy(\"PJOTR\").agg(F.sum(\"Spend\").alias(\"Total Spend\"), F.sum(\"Records\").alias(\"Total Records\"))\n    logger.info(\"Summarize transformation applied.\")\nexcept Exception as e:\n    logger.error(f\"Error in summarize transformation: {e}\")\n    raise\n\n# Output Handling\ntry:\n    target_catalog = \"catalog_name\"\n    target_schema = \"schema_name\"\n    \n    # Ensure schema exists before creating table\n    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {target_catalog}.{target_schema}\")\n    logger.info(f\"Schema {target_catalog}.{target_schema} ensured\")\n    \n    # Write to Unity Catalog target table (overwrite mode handles table replacement)\n    summarized_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{target_catalog}.{target_schema}.C03_pjotr\")\n    pjotr_in_pes_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{target_catalog}.{target_schema}.PJOTR_in_PES\")\n    \n    unmapped_df = filtered_df.filter(filtered_df[\"Business unit\"] == \"UNMAPPED\")\n    unmapped_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{target_catalog}.{target_schema}.C03_unmapped_to_PJOTR\")\n    \n    union_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{target_catalog}.{target_schema}.C03_pjotr_midway\")\n    logger.info(\"Data written to Unity Catalog target tables successfully.\")\nexcept Exception as e:\n    logger.error(f\"Error in output handling: {e}\")\n    raise\n\n# Additional logging for permissions check\nlogger.info(\"Ensure that the user has the necessary permissions to access the specified DBFS paths.\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}