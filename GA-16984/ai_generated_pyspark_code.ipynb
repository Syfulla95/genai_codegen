{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nfrom pyspark.sql import functions as F\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Function to load data from MySQL\ndef load_mysql_data(query, secret_scope, secret_key):\n    try:\n        # Retrieve credentials securely\n        user = dbutils.secrets.get(secret_scope, f\"{secret_key}_user\")\n        password = dbutils.secrets.get(secret_scope, f\"{secret_key}_password\")\n        host = dbutils.secrets.get(secret_scope, f\"{secret_key}_host\")\n        database = dbutils.secrets.get(secret_scope, f\"{secret_key}_database\")\n        \n        # Connect to MySQL and fetch data using JDBC\n        jdbc_url = f\"jdbc:mysql://{host}/{database}\"\n        df = spark.read.format(\"jdbc\").option(\"url\", jdbc_url) \\\n            .option(\"dbtable\", f\"({query}) as t\").option(\"user\", user).option(\"password\", password).load()\n        \n        logger.info(f\"Loaded data from MySQL with query: {query}\")\n        logger.info(f\"Schema: {df.schema}\")\n        logger.info(f\"Record count: {df.count()}\")\n        return df\n    except Exception as e:\n        logger.error(f\"Error loading data from MySQL: {str(e)}\")\n        raise\n\n# Function to load data from Unity Catalog\ndef load_unity_catalog_data(table_path):\n    try:\n        # Correct the table path syntax for Unity Catalog\n        df = spark.table(table_path)\n        logger.info(f\"Loaded data from Unity Catalog table: {table_path}\")\n        logger.info(f\"Schema: {df.schema}\")\n        logger.info(f\"Record count: {df.count()}\")\n        return df\n    except Exception as e:\n        logger.error(f\"Error loading data from Unity Catalog: {str(e)}\")\n        raise\n\n# Function to apply transformations\ndef apply_transformations(df):\n    try:\n        # Example transformation: Clean and transform multiple fields\n        df_transformed = df.withColumn(\"field\", F.when(F.col(\"field\").contains(\"#\"), None)\n                                        .when(F.col(\"field\").contains(\"UNMAPPED\"), None)\n                                        .when(F.col(\"field\").contains(\"NULL\"), None)\n                                        .otherwise(F.col(\"field\"))) \\\n                           .withColumn(\"field\", F.when(F.col(\"field\").startswith(\"00\"), F.expr(\"substring(field, 3, length(field))\"))\n                                        .otherwise(F.col(\"field\")))\n        \n        logger.info(\"Applied transformations\")\n        logger.info(f\"Schema after transformation: {df_transformed.schema}\")\n        logger.info(f\"Record count after transformation: {df_transformed.count()}\")\n        return df_transformed\n    except Exception as e:\n        logger.error(f\"Error applying transformations: {str(e)}\")\n        raise\n\n# Function to perform join operations\ndef perform_joins(df1, df2, join_condition):\n    try:\n        df_joined = df1.join(df2, join_condition, \"inner\")\n        logger.info(\"Performed join operation\")\n        logger.info(f\"Schema after join: {df_joined.schema}\")\n        logger.info(f\"Record count after join: {df_joined.count()}\")\n        return df_joined\n    except Exception as e:\n        logger.error(f\"Error performing join operation: {str(e)}\")\n        raise\n\n# Function to write data to Unity Catalog\ndef write_to_unity_catalog(df, catalog, schema, table):\n    try:\n        # Ensure schema exists\n        spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema}\")\n        logger.info(f\"Schema {catalog}.{schema} ensured\")\n        \n        # Write data to Unity Catalog table\n        df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{catalog}.{schema}.{table}\")\n        logger.info(f\"Data written to Unity Catalog table: {catalog}.{schema}.{table}\")\n    except Exception as e:\n        logger.error(f\"Error writing data to Unity Catalog: {str(e)}\")\n        raise\n\n# Load data from various sources\nmysql_df_99 = None\ntext_input_df_330 = None\ntry:\n    mysql_df_99 = load_mysql_data(\"select pjotr_prod.* from pjotr_prod\", \"mysql_scope\", \"pjotr_dev\")\nexcept Exception as e:\n    logger.error(f\"Failed to load MySQL data for Node 99: {str(e)}\")\n\ntry:\n    # Correct the table path syntax for Unity Catalog\n    text_input_df_330 = load_unity_catalog_data(\"catalog.schema.TextInput\")\nexcept Exception as e:\n    logger.error(f\"Failed to load Unity Catalog data for Node 330: {str(e)}\")\n\n# Apply transformations\ntransformed_df = None\nif mysql_df_99 is not None:\n    try:\n        transformed_df = apply_transformations(mysql_df_99)\n    except Exception as e:\n        logger.error(f\"Failed to apply transformations: {str(e)}\")\n\n# Perform join operations\njoined_df = None\nif transformed_df is not None and text_input_df_330 is not None:\n    try:\n        joined_df = perform_joins(transformed_df, text_input_df_330, \"join_field\")\n    except Exception as e:\n        logger.error(f\"Failed to perform join operations: {str(e)}\")\n\n# Write output to Unity Catalog\nif joined_df is not None:\n    try:\n        write_to_unity_catalog(joined_df, \"catalog_name\", \"schema_name\", \"C03_pjotr\")\n    except Exception as e:\n        logger.error(f\"Failed to write data to Unity Catalog: {str(e)}\")\n\n# Corrected code to handle secret and table access issues\n# 1. Ensure the secret scope and keys are correctly configured in Databricks.\n# 2. Verify the Unity Catalog table path is correct and accessible.\n\n# Additional logging and error handling added to ensure robustness in Databricks environment.\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}