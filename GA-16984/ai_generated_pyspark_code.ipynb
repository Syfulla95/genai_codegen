{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nfrom pyspark.sql import functions as F\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ntry:\n    # Load PES_prep.yxdb from Unity Catalog\n    pes_prep_df = spark.table(\"genai_demo.jnj.pes_prep\")\n    logger.info(f\"PES_prep.yxdb loaded with {pes_prep_df.count()} records\")\n    pes_prep_df.printSchema()\n\n    # Apply multi-field formula transformation\n    # Assuming transformation involves trimming and removing specific values\n    pes_prep_transformed_df = pes_prep_df.withColumn(\"Business unit code\", F.trim(F.col(\"Business unit code\"))) \\\n                                         .withColumn(\"FMRC code\", F.trim(F.col(\"FMRC code\"))) \\\n                                         .withColumn(\"FSID code\", F.trim(F.col(\"FSID code\"))) \\\n                                         .withColumn(\"LE code\", F.trim(F.col(\"LE code\"))) \\\n                                         .withColumn(\"MRC code\", F.trim(F.col(\"MRC code\"))) \\\n                                         .withColumn(\"Plant code\", F.trim(F.col(\"Plant code\"))) \\\n                                         .withColumn(\"PO business unit code\", F.trim(F.col(\"PO business unit code\"))) \\\n                                         .withColumn(\"PO LE code\", F.trim(F.col(\"PO LE code\"))) \\\n                                         .withColumn(\"PO MRC code\", F.trim(F.col(\"PO MRC code\"))) \\\n                                         .withColumn(\"PO site code\", F.trim(F.col(\"PO site code\"))) \\\n                                         .withColumn(\"Site code\", F.trim(F.col(\"Site code\"))) \\\n                                         .withColumn(\"Vision sourced data\", F.trim(F.col(\"Vision sourced data\")))\n    logger.info(f\"Multi-field formula transformation applied with {pes_prep_transformed_df.count()} records\")\n\n    # Apply select transformation\n    pes_prep_selected_df = pes_prep_transformed_df.select(\"Business unit code\", \"FMRC code\", \"FSID code\", \"LE code\", \n                                                          \"MRC code\", \"Plant code\", \"PO business unit code\", \"PO LE code\", \n                                                          \"PO MRC code\", \"PO site code\", \"Site code\", \"Vision sourced data\")\n    pes_prep_selected_df.printSchema()\n\n    # Load C19_ivl_data.yxdb from Unity Catalog\n    c19_ivl_data_df = spark.table(\"genai_demo.jnj.c19_ivl_data\")\n    logger.info(f\"C19_ivl_data.yxdb loaded with {c19_ivl_data_df.count()} records\")\n    c19_ivl_data_df.printSchema()\n\n    # Apply select transformation on C19_ivl_data.yxdb\n    c19_ivl_selected_df = c19_ivl_data_df.select(\"PES ID\", \"Invoice source system\", \"IVL business unit code\")\n    c19_ivl_selected_df.printSchema()\n\n    # Join PES_prep.yxdb with C19_ivl_data.yxdb on PES ID\n    joined_df = pes_prep_selected_df.join(c19_ivl_selected_df, on=\"PES ID\", how=\"inner\").drop(c19_ivl_selected_df[\"PES ID\"])\n    logger.info(f\"Join operation completed with {joined_df.count()} records\")\n    joined_df.printSchema()\n\n    # Apply formula transformation (custom calculations)\n    # Assuming custom calculations involve creating/modifying fields\n    formula_df = joined_df.withColumn(\"New Field\", F.expr(\"some_custom_calculation\"))\n    logger.info(f\"Formula transformation applied with {formula_df.count()} records\")\n    formula_df.printSchema()\n\n    # Apply union transformation\n    # Assuming union involves merging with another DataFrame (not specified in plan)\n    # For demonstration, using the same DataFrame\n    union_df = formula_df.union(formula_df)\n    logger.info(f\"Union transformation applied with {union_df.count()} records\")\n    union_df.printSchema()\n\n    # Apply filter transformation\n    filtered_df = union_df.filter(F.col(\"POrg\") == 'P001')\n    logger.info(f\"Filter transformation applied with {filtered_df.count()} records\")\n\n    # Apply summarize transformation\n    summarized_df = filtered_df.groupBy(\"PJOTR\").agg(F.sum(\"Spend\").alias(\"sum_Spend\"), F.sum(\"Records\").alias(\"sum_Records\"))\n    logger.info(f\"Summarize transformation applied with {summarized_df.count()} records\")\n    summarized_df.printSchema()\n\n    # Output results to C03_pjotr.yxdb\n    target_catalog = \"genai_demo\"\n    target_schema = \"jnj\"\n    target_table = \"c03_pjotr\"\n\n    # Ensure schema exists before creating table\n    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {target_catalog}.{target_schema}\")\n    logger.info(f\"Schema {target_catalog}.{target_schema} ensured\")\n\n    # Write to Unity Catalog target table (overwrite mode handles table replacement)\n    summarized_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{target_catalog}.{target_schema}.{target_table}\")\n    logger.info(f\"Data written to {target_catalog}.{target_schema}.{target_table}\")\n\nexcept Exception as e:\n    logger.error(f\"An error occurred: {str(e)}\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}