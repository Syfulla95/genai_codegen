{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nfrom pyspark.sql import functions as F\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Step 1: Source Extraction\ntry:\n    # Extract data from Unity Catalog tables\n    pes_prep_df = spark.table(\"genai_demo.jnj.pes_prep\")\n    c19_ivl_data_df = spark.table(\"genai_demo.jnj.c19_ivl_data\")\n    c04_ekpo_df = spark.table(\"genai_demo.jnj.c04_ekpo\")\n    c04_bseg_df = spark.table(\"genai_demo.jnj.c04_bseg\")\n    pjotr_df = spark.table(\"genai_demo.jnj.pjotr_\")\n    pjotr_in_pes_df = spark.table(\"genai_demo.jnj.pjotr_in_pes\")\n\n    # Log record count and schema\n    logger.info(f\"PES_prep: {pes_prep_df.count()} records, Schema: {pes_prep_df.schema}\")\n    logger.info(f\"C19_ivl_data: {c19_ivl_data_df.count()} records, Schema: {c19_ivl_data_df.schema}\")\n    logger.info(f\"C04_EKPO: {c04_ekpo_df.count()} records, Schema: {c04_ekpo_df.schema}\")\n    logger.info(f\"C04_BSEG: {c04_bseg_df.count()} records, Schema: {c04_bseg_df.schema}\")\n    logger.info(f\"PJOTR_: {pjotr_df.count()} records, Schema: {pjotr_df.schema}\")\n    logger.info(f\"PJOTR_in_PES: {pjotr_in_pes_df.count()} records, Schema: {pjotr_in_pes_df.schema}\")\nexcept Exception as e:\n    logger.error(f\"Error in Source Extraction: {str(e)}\")\n    raise\n\n# Step 2: Transformation - Multi-Field Formula\ntry:\n    # Example transformation: trimming and removing specific values\n    pes_prep_df = pes_prep_df.withColumn(\"trimmed_field\", F.trim(F.col(\"field_name\"))).drop(\"irrelevant_column\")\n    c19_ivl_data_df = c19_ivl_data_df.withColumn(\"cleaned_field\", F.when(F.col(\"field_name\") != \"unwanted_value\", F.col(\"field_name\")))\n\n    # Log record count and schema\n    logger.info(f\"PES_prep after transformation: {pes_prep_df.count()} records, Schema: {pes_prep_df.schema}\")\n    logger.info(f\"C19_ivl_data after transformation: {c19_ivl_data_df.count()} records, Schema: {c19_ivl_data_df.schema}\")\nexcept Exception as e:\n    logger.error(f\"Error in Multi-Field Formula Transformation: {str(e)}\")\n    raise\n\n# Step 3: Transformation - Select\ntry:\n    # Select specific fields\n    pes_prep_selected_df = pes_prep_df.select(\"field1\", \"field2\")\n    c19_ivl_data_selected_df = c19_ivl_data_df.select(\"field3\", \"field4\")\n\n    # Log record count and schema\n    logger.info(f\"PES_prep after selection: {pes_prep_selected_df.count()} records, Schema: {pes_prep_selected_df.schema}\")\n    logger.info(f\"C19_ivl_data after selection: {c19_ivl_data_selected_df.count()} records, Schema: {c19_ivl_data_selected_df.schema}\")\nexcept Exception as e:\n    logger.error(f\"Error in Select Transformation: {str(e)}\")\n    raise\n\n# Step 4: Transformation - Join\ntry:\n    # Perform join operations\n    joined_df = pes_prep_selected_df.join(c19_ivl_data_selected_df, pes_prep_selected_df.field1 == c19_ivl_data_selected_df.field3, \"inner\")\n\n    # Drop or rename duplicate columns\n    joined_df = joined_df.drop(c19_ivl_data_selected_df.field3)\n\n    # Log record count and schema\n    logger.info(f\"Joined DataFrame: {joined_df.count()} records, Schema: {joined_df.schema}\")\nexcept Exception as e:\n    logger.error(f\"Error in Join Transformation: {str(e)}\")\n    raise\n\n# Step 5: Transformation - Formula\ntry:\n    # Apply custom calculations\n    formula_df = joined_df.withColumn(\"new_field\", F.col(\"field1\") + F.col(\"field2\"))\n\n    # Log record count and schema\n    logger.info(f\"DataFrame after formula application: {formula_df.count()} records, Schema: {formula_df.schema}\")\nexcept Exception as e:\n    logger.error(f\"Error in Formula Transformation: {str(e)}\")\n    raise\n\n# Step 6: Transformation - Union\ntry:\n    # Merge multiple data streams\n    union_df = formula_df.union(pjotr_df)\n\n    # Log record count and schema\n    logger.info(f\"DataFrame after union: {union_df.count()} records, Schema: {union_df.schema}\")\nexcept Exception as e:\n    logger.error(f\"Error in Union Transformation: {str(e)}\")\n    raise\n\n# Step 7: Transformation - Filter\ntry:\n    # Apply filter conditions\n    filtered_df = union_df.filter(F.col(\"new_field\") > 100)\n\n    # Log record count and schema\n    logger.info(f\"DataFrame after filtering: {filtered_df.count()} records, Schema: {filtered_df.schema}\")\nexcept Exception as e:\n    logger.error(f\"Error in Filter Transformation: {str(e)}\")\n    raise\n\n# Step 8: Transformation - Summarize\ntry:\n    # Aggregate data\n    summary_df = filtered_df.groupBy(\"field1\").agg(F.sum(\"new_field\").alias(\"sum_new_field\"))\n\n    # Log record count and schema\n    logger.info(f\"DataFrame after summarization: {summary_df.count()} records, Schema: {summary_df.schema}\")\nexcept Exception as e:\n    logger.error(f\"Error in Summarize Transformation: {str(e)}\")\n    raise\n\n# Step 9: Output Loading\ntry:\n    # Ensure schema exists before creating table\n    target_catalog = \"genai_demo\"\n    target_schema = \"jnj\"\n    target_table = \"target_table\"\n\n    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {target_catalog}.{target_schema}\")\n    logger.info(f\"Schema {target_catalog}.{target_schema} ensured\")\n\n    # Write to Unity Catalog target table\n    summary_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{target_catalog}.{target_schema}.{target_table}\")\n\n    # Log record count and schema\n    logger.info(f\"Data loaded to {target_catalog}.{target_schema}.{target_table}: {summary_df.count()} records, Schema: {summary_df.schema}\")\nexcept Exception as e:\n    logger.error(f\"Error in Output Loading: {str(e)}\")\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}