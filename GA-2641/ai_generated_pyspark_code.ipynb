{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# COMMAND ----------\n# MAGIC %md\n# MAGIC # ETL Process for Customer 360 View\n# MAGIC This notebook performs an ETL process to create a comprehensive Customer 360 view by integrating data from various sources.\n\n# COMMAND ----------\n# MAGIC\n",
                "# Import necessary libraries\nimport logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import count, max, avg, datediff, current_date, when, lit\n\n# COMMAND ----------\n# MAGIC\n",
                "# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n# MAGIC\n",
                "try:\n    # Load data from Unity Catalog tables\n    logger.info(\"Loading data from Unity Catalog tables...\")\n    claims_df = spark.table(\"genai_demo.jnj.claims\")\n    demographics_df = spark.table(\"genai_demo.jnj.demographics\")\n    policy_df = spark.table(\"genai_demo.jnj.policy\")\n    scores_df = spark.table(\"genai_demo.jnj.scores\")\n    aiml_insights_df = spark.table(\"genai_demo.jnj.aiml_insights\")\n\n# COMMAND ----------\n# MAGIC\n",
                "# Select relevant fields from demographics data\n    logger.info(\"Selecting relevant fields from demographics data for customer insights...\")\n    selected_demographics_df = demographics_df.select(\n        \"Customer_ID\", \"Customer_Name\", \"Email\", \"Phone_Number\", \"Address\", \"City\", \"State\", \"Postal_Code\",\n        \"Date_of_Birth\", \"Gender\", \"Marital_Status\", \"Occupation\", \"Income_Level\", \"Customer_Segment\"\n    )\n\n# COMMAND ----------\n# MAGIC\n",
                "# Select relevant fields from claims data\n    logger.info(\"Selecting relevant fields from claims data for claims analysis...\")\n    selected_claims_df = claims_df.select(\n        \"Claim_ID\", \"Policy_ID\", \"Claim_Date\", \"Claim_Type\", \"Claim_Status\", \"Claim_Amount\", \"Claim_Payout\"\n    )\n\n# COMMAND ----------\n# MAGIC\n",
                "# Inner join demographics and policy data on Customer_ID\n    logger.info(\"Joining demographics and policy data on Customer_ID to link customer and policy information...\")\n    demographics_policy_df = selected_demographics_df.join(policy_df, \"Customer_ID\", \"inner\")\n\n# COMMAND ----------\n# MAGIC\n",
                "# Inner join the result with claims data on Policy_ID\n    logger.info(\"Joining the result with claims data on Policy_ID to associate claims with policies...\")\n    joined_df = demographics_policy_df.join(selected_claims_df, \"Policy_ID\", \"inner\")\n\n# COMMAND ----------\n# MAGIC\n",
                "# Aggregate data to calculate metrics\n    logger.info(\"Aggregating data to calculate metrics such as total claims and average claim amount...\")\n    summarized_df = joined_df.groupBy(\"Customer_ID\").agg(\n        count(\"Claim_ID\").alias(\"Total_Claims\"),\n        count(\"Policy_ID\").alias(\"Policy_Count\"),\n        max(\"Claim_Date\").alias(\"Recent_Claim_Date\"),\n        avg(\"Claim_Amount\").alias(\"Average_Claim_Amount\")\n    )\n\n# COMMAND ----------\n# MAGIC\n",
                "# Inner join summarized data with the previous join result on Customer_ID\n    logger.info(\"Joining summarized data with the previous join result on Customer_ID for comprehensive metrics...\")\n    final_joined_df = summarized_df.join(joined_df, \"Customer_ID\", \"inner\")\n\n# COMMAND ----------\n# MAGIC\n",
                "# Calculate additional metrics\n    logger.info(\"Calculating additional metrics for customer insights...\")\n    age_calculation = datediff(current_date(), F.col(\"Date_of_Birth\")) / 365\n    claim_to_premium_ratio = when(F.col(\"Total_Premium_Paid\") > 0, F.col(\"Claim_Amount\") / F.col(\"Total_Premium_Paid\")).otherwise(0)\n    claims_per_policy = when(F.col(\"Policy_Count\") > 0, F.col(\"Total_Claims\") / F.col(\"Policy_Count\")).otherwise(0)\n\n    final_joined_df = final_joined_df.withColumn(\"Age\", age_calculation)\n    final_joined_df = final_joined_df.withColumn(\"Claim_To_Premium_Ratio\", claim_to_premium_ratio)\n    final_joined_df = final_joined_df.withColumn(\"Claims_Per_Policy\", claims_per_policy)\n    final_joined_df = final_joined_df.withColumn(\"Retention_Rate\", lit(0.85))\n    final_joined_df = final_joined_df.withColumn(\"Cross_Sell_Opportunities\", lit(\"MultiPolicy Discount, Home Coverage Addon\"))\n    final_joined_df = final_joined_df.withColumn(\"Upsell_Potential\", lit(\"Premium Vehicle Coverage\"))\n\n# COMMAND ----------\n# MAGIC\n",
                "# Combine data from multiple sources including AIML insights and scores\n    logger.info(\"Combining data from multiple sources including AIML insights and scores for a 360-degree customer view...\")\n    customer_360_df = final_joined_df.join(scores_df, \"Customer_ID\", \"inner\").join(aiml_insights_df, \"Customer_ID\", \"inner\")\n\n# COMMAND ----------\n# MAGIC\n",
                "# Write the final DataFrame to the Customer 360 view table in Databricks\n    logger.info(\"Writing the final DataFrame to the Customer 360 view table in Databricks...\")\n    spark.sql(\"DROP TABLE IF EXISTS genai_demo.jnj.customer_360_view\")\n    customer_360_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.jnj.customer_360_view\")\n\n    logger.info(\"ETL process completed successfully.\")\n\nexcept Exception as e:\n    logger.error(\"An error occurred during the ETL process\", exc_info=True)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}