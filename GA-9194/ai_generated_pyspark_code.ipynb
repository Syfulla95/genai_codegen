{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC # ETL Migration Process\n# MAGIC This notebook performs an ETL migration process using PySpark. It loads data from a flat file and a SQL Server database, performs transformations, and writes the transformed data to a target database.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Import necessary libraries\nimport logging\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.utils import AnalysisException\n\n# Initialize logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Define JDBC connection properties\njdbc_url = \"jdbc:sqlserver://vsco-sqlserver.ctiklfxgg9js.us-east-2.rds.amazonaws.com;databaseName=vsco\"\nconnection_properties = {\n    \"user\": dbutils.secrets.get(scope=\"SSIS\", key=\"username\"),\n    \"password\": dbutils.secrets.get(scope=\"SSIS\", key=\"password\"),\n    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n}\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Function to load data from flat file\ndef load_flat_file_data(spark):\n    logger.info(\"Loading data from flat file source with explicit schema contract.\")\n    return spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/Volumes/genai_demo/ssis/ssis/SampleCurrencyData.txt\").select('AverageRate', 'CurrencyID', 'CurrencyDate', 'EndOfDayRate')\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Function to load data from AdventureWorksDW2012 database\ndef load_adventureworks_data(spark, jdbc_url, connection_properties):\n    logger.info(\"Loading data from AdventureWorksDW2012 database.\")\n    adventureworks_df = spark.read.jdbc(url=jdbc_url, table=\"dbo.DimCurrency1\", properties=connection_properties)\n    date_df = spark.read.jdbc(url=jdbc_url, table=\"dbo.DimDate1\", properties=connection_properties)\n    return adventureworks_df, date_df\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Function to perform lookup transformations\ndef perform_lookup_transformations(flat_file_df, adventureworks_df, date_df):\n    logger.info(\"Performing lookup transformations using explicit column selection.\")\n    enriched_df = flat_file_df.join(adventureworks_df, col('CurrencyID') == col('CurrencyAlternateKey'), \"inner\")\n    final_df = enriched_df.join(date_df, col('CurrencyDate') == col('FullDateAlternateKey'), \"inner\")\n    return final_df\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Function to write transformed data to target database\ndef write_transformed_data(spark, final_df):\n    logger.info(\"Dropping existing table if exists.\")\n    spark.sql(\"DROP TABLE IF EXISTS catalog.target_db.TransformedData\")\n    logger.info(\"Writing transformed data to the target database.\")\n    final_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.target_db.TransformedData\")\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Main ETL process\ntry:\n    # Load data\n    flat_file_df = load_flat_file_data(spark)\n    adventureworks_df, date_df = load_adventureworks_data(spark, jdbc_url, connection_properties)\n    \n    # Transform data\n    final_df = perform_lookup_transformations(flat_file_df, adventureworks_df, date_df)\n    \n    # Write data\n    write_transformed_data(spark, final_df)\n\nexcept AnalysisException as e:\n    logger.error(f\"AnalysisException occurred: {e}\")\nexcept Exception as e:\n    logger.error(f\"An error occurred: {e}\")\n\nlogger.info(\"ETL process completed successfully.\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}