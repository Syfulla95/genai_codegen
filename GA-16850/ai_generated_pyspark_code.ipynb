{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nfrom pyspark.sql import functions as F\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ntry:\n    # Load data from Unity Catalog tables\n    hospital_stats_df = spark.table(\"catalog.db.hospital_stats_north_america\")\n    sales_associates_df = spark.table(\"catalog.db.sales_associates_employment_details\")\n    compensation_guidelines_df = spark.table(\"catalog.db.compensation_guidelines\")\n    hospital_sales_assignments_df = spark.table(\"catalog.db.hospital_sales_assignments\")\n    logistics_channels_df = spark.table(\"catalog.db.logistics_channels\")\n    growth_opportunities_df = spark.table(\"catalog.db.growth_opportunities\")\n    third_party_sales_trends_df = spark.table(\"catalog.db.third_party_sales_trends\")\n    historical_sales_df = spark.table(\"catalog.db.historical_sales\")\n    company_goals_df = spark.table(\"catalog.db.company_goals\")\n\n    # Step 1: Join Sales Associates with Compensation Guidelines\n    sales_compensation_df = sales_associates_df.join(\n        compensation_guidelines_df, \"Associate_ID\", \"inner\"\n    ).withColumn(\n        \"Compensation\",\n        F.col(\"Base_Salary\") + (F.col(\"Commission_Percentage\") * F.col(\"Base_Salary\")) + F.col(\"Bonus\")\n    )\n\n    # Step 2: Join Hospital Stats with Hospital Sales Assignments\n    hospital_sales_df = hospital_stats_df.join(\n        hospital_sales_assignments_df, [\"Hospital_ID\", \"Hospital_Name\"], \"inner\"\n    )\n\n    # Step 3: Join the above two results on Associate_ID and Associate_Name\n    combined_df = sales_compensation_df.join(\n        hospital_sales_df, [\"Associate_ID\", \"Associate_Name\"], \"inner\"\n    )\n\n    # Step 4: Join Logistics Channels with Growth Opportunities\n    logistics_growth_df = logistics_channels_df.join(\n        growth_opportunities_df, [\"Channel_ID\", \"Channel_Type\"], \"inner\"\n    )\n\n    # Step 5: Unique Tool\n    unique_logistics_growth_df = logistics_growth_df.dropDuplicates([\"Channel_ID\", \"Channel_Type\", \"Hospital_ID\"])\n\n    # Step 6: Join the result with the previous join result on Hospital_ID\n    enriched_df = combined_df.join(\n        unique_logistics_growth_df, \"Hospital_ID\", \"inner\"\n    )\n\n    # Step 7: Join Historical Sales with Third Party Sales Trends\n    sales_trends_df = historical_sales_df.join(\n        third_party_sales_trends_df, \"Channel_Type\", \"inner\"\n    )\n\n    # Step 8: Unique Tool\n    unique_sales_trends_df = sales_trends_df.dropDuplicates([\"Year\", \"Channel_Type\", \"Sales_Revenue\"])\n\n    # Step 9: Generate Rows for Target Year\n    target_years_df = spark.range(2024, 2027).withColumnRenamed(\"id\", \"Target Year\")\n\n    # Step 10: Calculate Projected Revenue\n    projected_revenue_df = unique_sales_trends_df.crossJoin(target_years_df).withColumn(\n        \"Projected Revenue\",\n        F.when(F.col(\"Target Year\") == 2024, F.col(\"Sales_Revenue\") * (F.col(\"Projected_Sales_Growth_Rate\") / 100))\n        .when(F.col(\"Target Year\") == 2025, F.col(\"Sales_Revenue\") * (1 + F.col(\"Projected_Sales_Growth_Rate\") / 100))\n        .when(F.col(\"Target Year\") == 2026, F.col(\"Sales_Revenue\") * (1 + F.col(\"Projected_Sales_Growth_Rate\") / 100))\n        .otherwise(F.col(\"Sales_Revenue\"))\n    )\n\n    # Step 11: Calculate Projected Sales Growth Rate\n    projected_growth_rate_df = projected_revenue_df.withColumn(\n        \"Projected_Sales_Growth_Rate\",\n        F.when(F.col(\"Target Year\") == 2024, F.col(\"Projected_Growth_Rate\") + (F.col(\"Projected_Growth_Rate\") / 100))\n        .when(F.col(\"Target Year\") == 2025, (F.col(\"Projected_Growth_Rate\") + (F.col(\"Projected_Growth_Rate\") / 100)) + (F.col(\"Projected_Growth_Rate\") / 100))\n        .when(F.col(\"Target Year\") == 2026, ((F.col(\"Projected_Growth_Rate\") + (F.col(\"Projected_Growth_Rate\") / 100)) + (F.col(\"Projected_Growth_Rate\") / 100)) + (F.col(\"Projected_Growth_Rate\") / 100))\n        .otherwise(F.col(\"Projected_Growth_Rate\"))\n    )\n\n    # Step 12: Calculate Projected Investments\n    projected_investments_df = projected_growth_rate_df.withColumn(\n        \"projected_investments\",\n        F.when(F.col(\"Target Year\") == 2024, F.col(\"Investment_Planned\") * (F.col(\"Projected_Sales_Growth_Rate\") / 100))\n        .when(F.col(\"Target Year\") == 2025, F.col(\"Investment_Planned\") * (1 + F.col(\"Projected_Sales_Growth_Rate\") / 100))\n        .when(F.col(\"Target Year\") == 2026, F.col(\"Investment_Planned\") * (1 + F.col(\"Projected_Sales_Growth_Rate\") / 100))\n        .otherwise(F.col(\"Investment_Planned\"))\n    )\n\n    # Step 13: Sort by Target Year\n    final_df = projected_investments_df.orderBy(\"Target Year\")\n\n    # Write the final output to Unity Catalog table\n    spark.sql(\"DROP TABLE IF EXISTS catalog.db.target_sales_report\")\n    final_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.db.target_sales_report\")\n\n    logger.info(\"ETL process completed successfully and data written to target_sales_report table.\")\n\nexcept Exception as e:\n    logger.error(f\"An error occurred during the ETL process: {e}\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}