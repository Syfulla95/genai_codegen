{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, sum, avg\nimport logging\n\n# Initialize Spark session (assumed pre-initialized in Databricks)\n# spark = SparkSession.builder.getOrCreate()  # Not needed in Databricks\n\n# Initialize logger for Databricks environment\nlogger = logging.getLogger(\"DatabricksLogger\")\nlogger.setLevel(logging.INFO)\nhandler = logging.StreamHandler()\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nhandler.setFormatter(formatter)\nlogger.addHandler(handler)\n\n# Load data from Unity Catalog\ntry:\n    source_df = spark.table(\"source_catalog.source_db.source_table\")\n    logger.info(\"Successfully loaded source table from Unity Catalog\")\nexcept Exception as e:\n    logger.error(f\"Failed to load source table from Unity Catalog: {str(e)}\")\n    source_df = None\n\n# Load data from external PostgreSQL system\ntry:\n    # Ensure secrets are correctly set up in Databricks\n    jdbc_url = f\"jdbc:postgresql://legacy-db-host:5432/legacy_db\"\n    connection_properties = {\n        \"user\": dbutils.secrets.get(scope=\"my_scope\", key=\"legacy_db_user\"),\n        \"password\": dbutils.secrets.get(scope=\"my_scope\", key=\"legacy_db_password\")\n    }\n    external_df = spark.read.jdbc(url=jdbc_url, table=\"(SELECT * FROM legacy_table) AS legacy_table\", properties=connection_properties)\n    logger.info(\"Successfully loaded data from external PostgreSQL system\")\nexcept Exception as e:\n    logger.error(f\"Failed to load data from external PostgreSQL system: {str(e)}\")\n    external_df = None\n\n# Perform join operation\nif source_df is not None and external_df is not None:\n    try:\n        joined_df = source_df.alias(\"left_table\").join(\n            external_df.alias(\"right_table\"),\n            col(\"left_table.id\") == col(\"right_table.id\"),\n            how=\"inner\"\n        )\n        logger.info(\"Successfully performed join operation\")\n    except Exception as e:\n        logger.error(f\"Join operation failed: {str(e)}\")\n        joined_df = None\nelse:\n    logger.error(\"Join operation skipped due to missing DataFrames\")\n    joined_df = None\n\n# Filter the joined data\nif joined_df is not None:\n    try:\n        filtered_df = joined_df.filter(col(\"status\") == \"active\")\n        logger.info(\"Successfully filtered joined data\")\n    except Exception as e:\n        logger.error(f\"Filter operation failed: {str(e)}\")\n        filtered_df = None\nelse:\n    logger.error(\"Filter operation skipped due to missing joined DataFrame\")\n    filtered_df = None\n\n# Perform aggregation\nif filtered_df is not None:\n    try:\n        aggregated_df = filtered_df.groupBy(\"category\").agg(\n            sum(\"amount\").alias(\"total_amount\"),\n            avg(\"amount\").alias(\"average_amount\")\n        )\n        logger.info(\"Successfully performed aggregation\")\n    except Exception as e:\n        logger.error(f\"Aggregation operation failed: {str(e)}\")\n        aggregated_df = None\nelse:\n    logger.error(\"Aggregation operation skipped due to missing filtered DataFrame\")\n    aggregated_df = None\n\n# Write the result to Unity Catalog\nif aggregated_df is not None:\n    try:\n        spark.sql(\"CREATE SCHEMA IF NOT EXISTS target_catalog.target_db\")\n        logger.info(\"Schema ensured before table creation\")\n        aggregated_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"target_catalog.target_db.target_table\")\n        logger.info(\"Successfully wrote aggregated data to Unity Catalog\")\n    except Exception as e:\n        logger.error(f\"Failed to write data to Unity Catalog: {str(e)}\")\nelse:\n    logger.error(\"Write operation skipped due to missing aggregated DataFrame\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}