{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import IntegerType, DoubleType\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ntry:\n    # Load data from Unity Catalog tables\n    hospital_stats_df = spark.table(\"catalog.db.hospital_stats_north_america\")\n    sales_assignments_df = spark.table(\"catalog.db.hospital_sales_assignments\")\n    employment_details_df = spark.table(\"catalog.db.sales_associates_employment_details\")\n    compensation_guidelines_df = spark.table(\"catalog.db.compensation_guidelines\")\n    logistics_channels_df = spark.table(\"catalog.db.logistics_channels\")\n    growth_opportunities_df = spark.table(\"catalog.db.growth_opportunities\")\n    company_goals_df = spark.table(\"catalog.db.company_goals\")\n    historical_sales_df = spark.table(\"catalog.db.historical_sales\")\n    third_party_sales_trends_df = spark.table(\"catalog.db.third_party_sales_trends\")\n\n    # Join hospital statistics with sales assignments\n    hospital_sales_df = hospital_stats_df.join(\n        sales_assignments_df,\n        on=[\"Hospital_ID\", \"Hospital_Name\"],\n        how=\"inner\"\n    )\n\n    # Join employment details with compensation guidelines\n    employment_compensation_df = employment_details_df.join(\n        compensation_guidelines_df,\n        on=\"Associate_ID\",\n        how=\"inner\"\n    )\n\n    # Combine the results of previous joins\n    combined_df = hospital_sales_df.join(\n        employment_compensation_df,\n        on=[\"Associate_ID\", \"Associate_Name\"],\n        how=\"inner\"\n    )\n\n    # Calculate total compensation\n    combined_df = combined_df.withColumn(\n        \"Compensation\",\n        F.col(\"Base_Salary\") + (F.col(\"Commission_Percentage\") * F.col(\"Base_Salary\")) + F.col(\"Bonus\")\n    )\n\n    # Select relevant fields\n    selected_df = combined_df.select(\n        \"Associate_ID\", \"Associate_Name\", \"Compensation\", \"Director_Name\", \"Hospital_ID\", \"Manager_Name\"\n    )\n\n    # Join logistics channels with growth opportunities\n    logistics_growth_df = logistics_channels_df.join(\n        growth_opportunities_df,\n        on=[\"Channel_ID\", \"Channel_Type\", \"Hospital_ID\"],\n        how=\"inner\"\n    )\n\n    # Join compensation data with logistics and growth data\n    compensation_logistics_growth_df = selected_df.join(\n        logistics_growth_df,\n        on=\"Hospital_ID\",\n        how=\"inner\"\n    )\n\n    # Select fields for further processing\n    selected_logistics_df = compensation_logistics_growth_df.select(\n        \"Hospital_ID\", \"Channel_Type\", \"Growth_Opportunities\", \"Projected_Growth_Rate\"\n    )\n\n    # Join selected data with company goals\n    goals_df = selected_logistics_df.join(\n        company_goals_df,\n        on=[\"Hospital_ID\", \"Channel_Type\"],\n        how=\"inner\"\n    )\n\n    # Ensure unique records\n    unique_goals_df = goals_df.dropDuplicates([\"Hospital_ID\", \"Channel_Type\", \"Projected_Growth_Rate\", \"Investment_Planned\"])\n\n    # Join historical sales data with third-party sales trends\n    sales_trends_df = historical_sales_df.join(\n        third_party_sales_trends_df,\n        on=\"Channel_Type\",\n        how=\"inner\"\n    )\n\n    # Ensure unique sales records\n    unique_sales_df = sales_trends_df.dropDuplicates([\"Year\", \"Channel_Type\", \"Sales_Revenue\"])\n\n    # Join unique sales data with growth and investment data\n    final_join_df = unique_sales_df.join(\n        unique_goals_df,\n        on=[\"Hospital_ID\", \"Channel_ID\", \"Channel_Type\"],\n        how=\"inner\"\n    )\n\n    # Generate rows for target years\n    target_years_df = spark.range(2023, 2027).withColumnRenamed(\"id\", \"TargetYear\")\n\n    # Calculate projected sales growth rate\n    final_df = final_join_df.crossJoin(target_years_df).withColumn(\n        \"projected_sales_growth_rate\",\n        F.when(F.col(\"TargetYear\") == 2024, F.col(\"Projected_Growth_Rate\") + (F.col(\"Projected_Growth_Rate\") / 100))\n         .when(F.col(\"TargetYear\") == 2025, (F.col(\"Projected_Growth_Rate\") + (F.col(\"Projected_Growth_Rate\") / 100)) + (F.col(\"Projected_Growth_Rate\") / 100))\n         .when(F.col(\"TargetYear\") == 2026, ((F.col(\"Projected_Growth_Rate\") + (F.col(\"Projected_Growth_Rate\") / 100)) + (F.col(\"Projected_Growth_Rate\") / 100)) + (F.col(\"Projected_Growth_Rate\") / 100))\n         .otherwise(F.col(\"Projected_Growth_Rate\"))\n    )\n\n    # Calculate projected investments\n    final_df = final_df.withColumn(\n        \"projected_investments\",\n        F.when(F.col(\"TargetYear\") == 2024, F.col(\"Investment_Planned\") * (F.col(\"projected_sales_growth_rate\") / 100))\n         .when(F.col(\"TargetYear\") == 2025, F.col(\"Investment_Planned\") * (1 + F.col(\"projected_sales_growth_rate\") / 100))\n         .when(F.col(\"TargetYear\") == 2026, F.col(\"Investment_Planned\") * (1 + F.col(\"projected_sales_growth_rate\") / 100))\n         .otherwise(F.col(\"Investment_Planned\"))\n    )\n\n    # Calculate projected revenue\n    final_df = final_df.withColumn(\n        \"Projected_Revenue\",\n        F.when(F.col(\"TargetYear\") == 2024, F.col(\"Sales_Revenue\") * (F.col(\"projected_sales_growth_rate\") / 100))\n         .when(F.col(\"TargetYear\") == 2025, F.col(\"Sales_Revenue\") * (1 + F.col(\"projected_sales_growth_rate\") / 100))\n         .when(F.col(\"TargetYear\") == 2026, F.col(\"Sales_Revenue\") * (1 + F.col(\"projected_sales_growth_rate\") / 100))\n         .otherwise(F.col(\"Sales_Revenue\"))\n    )\n\n    # Filter records based on target year\n    filtered_df = final_df.filter(F.col(\"TargetYear\") > 2023)\n\n    # Select fields for final output\n    output_df = filtered_df.select(\n        \"Channel_Type\", \"Hospital_ID\", \"Market_Trend\", \"Political_Impact\", \"Economic_Impact\",\n        \"TargetYear\", \"projected_sales_growth_rate\", \"projected_investments\", \"Projected_Revenue\"\n    )\n\n    # Sort records by target year\n    sorted_output_df = output_df.orderBy(\"TargetYear\")\n\n    # Write to Unity Catalog target table\n    spark.sql(\"DROP TABLE IF EXISTS catalog.db.sales_prediction_output\")\n    sorted_output_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.db.sales_prediction_output\")\n\n    logger.info(\"ETL process completed successfully.\")\n\nexcept Exception as e:\n    logger.error(f\"Error during ETL process: {e}\")\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}