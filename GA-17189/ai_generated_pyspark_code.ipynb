{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\nfrom datetime import datetime, timedelta\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import StringType\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Function to safely get secrets\ndef get_secret(scope, key):\n    try:\n        return dbutils.secrets.get(scope, key)\n    except Exception as e:\n        logger.error(f\"Error retrieving secret {key} from scope {scope}: {str(e)}\")\n        raise\n\n# Load data from Unity Catalog tables\ntry:\n    text_input_df = spark.table(\"catalog.source_db.text_input_channel\")\n    manual_date_df = spark.table(\"catalog.source_db.manual_date_input\")\n    oct_tc3_df = spark.table(\"catalog.source_db.oct_tc3\")\n    week1_df = spark.table(\"catalog.source_db.dynamic_input_week1\")\n    week2_df = spark.table(\"catalog.source_db.dynamic_input_week2\")\n    week3_df = spark.table(\"catalog.source_db.dynamic_input_week3\")\n    week4_df = spark.table(\"catalog.source_db.dynamic_input_week4\")\n    week5_df = spark.table(\"catalog.source_db.dynamic_input_week5\")\n    logger.info(\"Data loaded from Unity Catalog tables successfully\")\nexcept Exception as e:\n    logger.error(f\"Error loading data from Unity Catalog tables: {str(e)}\")\n    raise\n\n# Transformation: Date Generation\ncurrent_date = datetime.now()\ndate_df = spark.createDataFrame([(current_date,)], [\"CurrentDate\"])\nlogger.info(\"Current date generated\")\n\n# Transformation: DateTime Format Conversion\ndate_df = date_df.withColumn(\"DateTime_Out\", F.date_format(\"CurrentDate\", \"yyyy-MM-dd\"))\nlogger.info(\"DateTime format conversion applied\")\n\n# Transformation: GroupBy and Summarize\ntry:\n    summarize_df = oct_tc3_df.groupBy(\"BILL_DTE\").agg(\n        F.sum(\"Invoices\").alias(\"Sum_Invoices\"),\n        F.sum(\"Invoice_Lines\").alias(\"Sum_Invoice_Lines\"),\n        F.sum(\"LANDED_COST\").alias(\"Sum_LANDED_COST\"),\n        F.sum(\"EXT_FINAL_PRICE\").alias(\"Sum_EXT_FINAL_PRICE\"),\n        F.sum(\"Trans_Charge_Amt\").alias(\"Sum_Trans_Charge_Amt\"),\n        F.sum(\"RESTOCK_Fee\").alias(\"Sum_RESTOCK_Fee\"),\n        F.sum(\"Special_Hndl_Amt\").alias(\"Sum_Special_Hndl_Amt\"),\n        F.sum(\"Vendor_Hndl_Amt\").alias(\"Sum_Vendor_Hndl_Amt\"),\n        F.sum(\"MOC_Amt\").alias(\"Sum_MOC_Amt\"),\n        F.sum(\"Fuel_Surcharge\").alias(\"Sum_Fuel_Surcharge\")\n    )\n    logger.info(\"Summarization applied successfully\")\nexcept Exception as e:\n    logger.error(f\"Error during summarization: {str(e)}\")\n    raise\n\n# Transformation: Date Calculations\ndate_calculations_df = date_df.withColumn(\"Prior_Week_Start\", F.date_sub(F.date_sub(F.date_format(\"DateTime_Out\", \"yyyy-MM-dd\"), F.dayofweek(\"DateTime_Out\")), 7)) \\\n    .withColumn(\"Prior_Week_End\", F.date_sub(F.date_sub(F.date_format(\"DateTime_Out\", \"yyyy-MM-dd\"), F.dayofweek(\"DateTime_Out\")), 1)) \\\n    .withColumn(\"Yesterday\", F.date_sub(F.date_format(\"DateTime_Out\", \"yyyy-MM-dd\"), 1)) \\\n    .withColumn(\"Today\", F.date_format(\"DateTime_Out\", \"yyyy-MM-dd\")) \\\n    .withColumn(\"P1M_Start\", F.add_months(F.date_format(\"DateTime_Out\", \"yyyy-MM-dd\"), -1)) \\\n    .withColumn(\"P1M_End\", F.date_sub(F.date_format(\"DateTime_Out\", \"yyyy-MM-dd\"), 1)) \\\n    .withColumn(\"P2M_Start\", F.add_months(F.date_format(\"DateTime_Out\", \"yyyy-MM-dd\"), -2)) \\\n    .withColumn(\"P2M_End\", F.date_sub(F.add_months(F.date_format(\"DateTime_Out\", \"yyyy-MM-dd\"), -1), 1)) \\\n    .withColumn(\"P3M_Start\", F.add_months(F.date_format(\"DateTime_Out\", \"yyyy-MM-dd\"), -3)) \\\n    .withColumn(\"P3M_End\", F.date_sub(F.add_months(F.date_format(\"DateTime_Out\", \"yyyy-MM-dd\"), -2), 1))\nlogger.info(\"Date calculations applied\")\n\n# Transformation: Union\ntry:\n    union_df = week1_df.union(week2_df).union(week3_df).union(week4_df).union(week5_df)\n    logger.info(\"Union operation applied successfully\")\nexcept Exception as e:\n    logger.error(f\"Error during union operation: {str(e)}\")\n    raise\n\n# Transformation: Custom Calculations\ntry:\n    union_df = union_df.withColumn(\"Rush_Order_Fee\", F.coalesce(F.col(\"ADDTN_TRANS_FEE_OVRRIDE_ZSRO\"), F.lit(0)))\n    logger.info(\"Custom calculations applied successfully\")\nexcept Exception as e:\n    logger.error(f\"Error during custom calculations: {str(e)}\")\n    raise\n\n# Transformation: Join\ntry:\n    join_df = union_df.join(text_input_df, union_df[\"DIST_CHNL_ID\"] == text_input_df[\"DIST_CHNL\"], \"left\")\n    logger.info(\"Join operation applied successfully\")\nexcept Exception as e:\n    logger.error(f\"Error during join operation: {str(e)}\")\n    raise\n\n# Transformation: Filter\ntry:\n    filter_df = join_df.filter(F.col(\"null_yn\") == 'Y')\n    logger.info(\"Filter operation applied successfully\")\nexcept Exception as e:\n    logger.error(f\"Error during filter operation: {str(e)}\")\n    raise\n\n# Transformation: Update Nulls\ntry:\n    update_nulls_df = filter_df.withColumn(\"FNC_ID\", F.when(F.isnull(F.col(\"FNC_ID\")) | (F.col(\"FNC_ID\") == \"\"), \"OTH\").otherwise(F.col(\"FNC_ID\"))) \\\n        .withColumn(\"FNC_DESC\", F.when(F.isnull(F.col(\"FNC_DESC\")) | (F.col(\"FNC_DESC\") == \"\"), \"OTHER\").otherwise(F.col(\"FNC_DESC\")))\n    logger.info(\"Update nulls operation applied successfully\")\nexcept Exception as e:\n    logger.error(f\"Error during update nulls operation: {str(e)}\")\n    raise\n\n# Transformation: Total Shipping and Handling\ntry:\n    total_shipping_df = update_nulls_df.withColumn(\"BIA_SHIP_HNDL_AMT\", F.expr(\"Sum_Trans_Charge_Amt + Sum_RESTOCK_Fee + Sum_Special_Hndl_Amt + Sum_Vendor_Hndl_Amt + Sum_MOC_Amt + Sum_Fuel_Surcharge\")) \\\n        .withColumn(\"COE_SHIP_HNDL_AMT\", F.expr(\"Sum_Trans_Charge_Amt + Sum_RESTOCK_Fee + Sum_Special_Hndl_Amt + Sum_Vendor_Hndl_Amt + Sum_MOC_Amt + Sum_Fuel_Surcharge + Rush_Order_Fee + VENDR_TRANS_CHRG_FRT_ZTV1 + MARKUP_VENDOR_TRANS_FEE_AMT_ZMT1\"))\n    logger.info(\"Total shipping and handling calculations applied successfully\")\nexcept Exception as e:\n    logger.error(f\"Error during total shipping and handling calculations: {str(e)}\")\n    raise\n\n# Transformation: Custom Formula\ntry:\n    invoice_sales_df = total_shipping_df.withColumn(\"Invoice_Sales\", F.col(\"Sum_EXT_FINAL_PRICE\"))\n    logger.info(\"Custom formula applied successfully\")\nexcept Exception as e:\n    logger.error(f\"Error during custom formula application: {str(e)}\")\n    raise\n\n# Write to Unity Catalog target table\ntry:\n    target_catalog = \"catalog_name\"\n    target_schema = \"schema_name\"\n    target_table = \"table_name\"\n    \n    # Create schema if it doesn't exist\n    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {target_catalog}.{target_schema}\")\n    logger.info(f\"Schema {target_catalog}.{target_schema} ensured\")\n    \n    # Write to Unity Catalog target table (overwrite mode handles table replacement)\n    invoice_sales_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{target_catalog}.{target_schema}.{target_table}\")\n    logger.info(f\"Data written to {target_catalog}.{target_schema}.{target_table} successfully\")\nexcept Exception as e:\n    logger.error(f\"Error writing data to Unity Catalog target table: {str(e)}\")\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}