{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC # ETL Process for Cardinal Health Data\n# MAGIC This notebook performs an ETL process on various datasets from Unity Catalog tables, integrating and transforming data for analysis.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Import necessary libraries\nimport logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import IntegerType, FloatType\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Load data from Unity Catalog tables\ndef load_data():\n    logger.info(\"Loading data from Unity Catalog tables...\")\n    hospital_stats_df = spark.table(\"genai_demo.cardinal_health.hospital_stats_north_america\")\n    sales_associates_df = spark.table(\"genai_demo.cardinal_health.SalesAssociates_EmploymentDetails\")\n    compensation_guidelines_df = spark.table(\"genai_demo.cardinal_health.Compensation_Guidelines\")\n    hospital_sales_assignments_df = spark.table(\"genai_demo.cardinal_health.HospitalSales_Assignments\")\n    logistics_channels_df = spark.table(\"genai_demo.cardinal_health.Logistics_Channels\")\n    growth_opportunities_df = spark.table(\"genai_demo.cardinal_health.Growth_Opportunities\")\n    third_party_sales_trends_df = spark.table(\"genai_demo.cardinal_health.ThirdParty_SalesTrends\")\n    historical_sales_df = spark.table(\"genai_demo.cardinal_health.Historical_Sales\")\n    company_goals_df = spark.table(\"genai_demo.cardinal_health.Company_Goals\")\n    return (hospital_stats_df, sales_associates_df, compensation_guidelines_df, hospital_sales_assignments_df,\n            logistics_channels_df, growth_opportunities_df, third_party_sales_trends_df, historical_sales_df, company_goals_df)\n\nhospital_stats_df, sales_associates_df, compensation_guidelines_df, hospital_sales_assignments_df, logistics_channels_df, growth_opportunities_df, third_party_sales_trends_df, historical_sales_df, company_goals_df = load_data()\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Data Integration: Join SalesAssociates_EmploymentDetails with Compensation_Guidelines\ndef integrate_compensation_data(sales_associates_df, compensation_guidelines_df):\n    logger.info(\"Joining SalesAssociates_EmploymentDetails with Compensation_Guidelines...\")\n    compensation_df = sales_associates_df.join(compensation_guidelines_df, \"Associate_ID\", \"inner\")\n    return compensation_df\n\ncompensation_df = integrate_compensation_data(sales_associates_df, compensation_guidelines_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Calculate total compensation to ensure accurate financial forecasting for associates\ndef calculate_total_compensation(compensation_df):\n    logger.info(\"Calculating total compensation...\")\n    compensation_df = compensation_df.withColumn(\n        \"Compensation\",\n        F.col(\"Base_Salary\").cast(FloatType()) +\n        (F.col(\"Commission_Percentage\").cast(FloatType()) * F.col(\"Base_Salary\").cast(FloatType())) +\n        F.col(\"Bonus\").cast(FloatType())\n    )\n    return compensation_df\n\ncompensation_df = calculate_total_compensation(compensation_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Join hospital_stats_north_america with HospitalSales_Assignments\ndef join_hospital_sales(hospital_stats_df, hospital_sales_assignments_df):\n    logger.info(\"Joining hospital_stats_north_america with HospitalSales_Assignments...\")\n    hospital_sales_df = hospital_stats_df.join(\n        hospital_sales_assignments_df,\n        [\"Hospital_ID\", \"Hospital_Name\"],\n        \"inner\"\n    )\n    return hospital_sales_df\n\nhospital_sales_df = join_hospital_sales(hospital_stats_df, hospital_sales_assignments_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Join the output of previous joins on Associate_ID and Associate_Name\ndef combine_data(compensation_df, hospital_sales_df):\n    logger.info(\"Joining previous outputs on Associate_ID and Associate_Name...\")\n    combined_df = compensation_df.join(\n        hospital_sales_df,\n        [\"Associate_ID\", \"Associate_Name\"],\n        \"inner\"\n    )\n    return combined_df\n\ncombined_df = combine_data(compensation_df, hospital_sales_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Select specific fields for further processing\ndef select_fields(combined_df):\n    logger.info(\"Selecting specific fields for further processing...\")\n    selected_df = combined_df.select(\n        \"Hospital_ID\", \"Director_Name\", \"Manager_Name\", \"Associate_ID\", \"Associate_Name\", \"Compensation\"\n    )\n    return selected_df\n\nselected_df = select_fields(combined_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Join with unique records from Logistics_Channels and Growth_Opportunities\ndef join_growth_opportunities(logistics_channels_df, growth_opportunities_df):\n    logger.info(\"Joining with unique records from Logistics_Channels and Growth_Opportunities...\")\n    unique_channels_df = logistics_channels_df.dropDuplicates([\"Channel_ID\", \"Channel_Type\", \"Hospital_ID\"])\n    growth_df = unique_channels_df.join(\n        growth_opportunities_df,\n        [\"Channel_ID\", \"Channel_Type\", \"Hospital_ID\"],\n        \"inner\"\n    )\n    return growth_df\n\ngrowth_df = join_growth_opportunities(logistics_channels_df, growth_opportunities_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Join with Historical_Sales and ThirdParty_SalesTrends\ndef join_sales_trends(historical_sales_df, third_party_sales_trends_df):\n    logger.info(\"Joining Historical_Sales with ThirdParty_SalesTrends...\")\n    sales_trends_df = historical_sales_df.join(\n        third_party_sales_trends_df,\n        \"Channel_Type\",\n        \"inner\"\n    )\n    return sales_trends_df\n\nsales_trends_df = join_sales_trends(historical_sales_df, third_party_sales_trends_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Calculate projected revenue based on target year\ndef calculate_projected_revenue(sales_trends_df):\n    logger.info(\"Calculating projected revenue based on target year...\")\n    projected_growth_rate = F.col(\"Projected_Growth_Rate\").cast(FloatType())\n    sales_revenue = F.col(\"Sales_Revenue\").cast(FloatType())\n    year_condition = F.col(\"Year\").cast(IntegerType()) > 2023\n\n    sales_trends_df = sales_trends_df.withColumn(\n        \"Projected_Revenue\",\n        F.when(year_condition, sales_revenue * (1 + projected_growth_rate))\n        .otherwise(sales_revenue)\n    )\n    return sales_trends_df\n\nsales_trends_df = calculate_projected_revenue(sales_trends_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Generate rows for target years\ndef generate_target_years(sales_trends_df):\n    logger.info(\"Generating rows for target years...\")\n    target_years_df = sales_trends_df.withColumn(\"Target_Year\", F.explode(F.array([2023, 2024, 2025, 2026])))\n    return target_years_df\n\ntarget_years_df = generate_target_years(sales_trends_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Filter records where Target Year is greater than 2023\ndef filter_target_years(target_years_df):\n    logger.info(\"Filtering records where Target Year is greater than 2023...\")\n    filtered_df = target_years_df.filter(target_years_df.Target_Year > 2023)\n    return filtered_df\n\nfiltered_df = filter_target_years(target_years_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Join with Company_Goals on Hospital_ID and Channel_Type\ndef join_company_goals(filtered_df, company_goals_df):\n    logger.info(\"Joining with Company_Goals on Hospital_ID and Channel_Type...\")\n    final_df = filtered_df.join(\n        company_goals_df,\n        [\"Hospital_ID\", \"Channel_Type\"],\n        \"inner\"\n    )\n    return final_df\n\nfinal_df = join_company_goals(filtered_df, company_goals_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Sort records by Target Year in ascending order\ndef sort_records(final_df):\n    logger.info(\"Sorting records by Target Year in ascending order...\")\n    sorted_df = final_df.sort(\"Target_Year\")\n    return sorted_df\n\nsorted_df = sort_records(final_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Define schema contract for final output\ndef define_schema_contract(sorted_df):\n    logger.info(\"Defining schema contract for final output...\")\n    final_df = sorted_df.select(\n        \"Hospital_ID\", \"Channel_Type\", \"Investment_Planned\", \"Sales_Revenue\", \"Market_Trend\", \"Political_Impact\",\n        \"Economic_Impact\", \"Target_Year\", \"Projected_Sales_Growth_Rate\", \"Projected_Revenue\"\n    )\n    return final_df\n\nfinal_df = define_schema_contract(sorted_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Write the final output to Unity Catalog table\ndef write_final_output(final_df):\n    logger.info(\"Writing the final output to Unity Catalog table...\")\n    spark.sql(\"DROP TABLE IF EXISTS genai_demo.cardinal_health.Target_sales\")\n    final_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.cardinal_health.Target_sales\")\n    logger.info(\"ETL process completed successfully.\")\n\nwrite_final_output(final_df)\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Handle exceptions\ndef handle_exceptions():\n    try:\n        # Execute all functions\n        hospital_stats_df, sales_associates_df, compensation_guidelines_df, hospital_sales_assignments_df, logistics_channels_df, growth_opportunities_df, third_party_sales_trends_df, historical_sales_df, company_goals_df = load_data()\n        compensation_df = integrate_compensation_data(sales_associates_df, compensation_guidelines_df)\n        compensation_df = calculate_total_compensation(compensation_df)\n        hospital_sales_df = join_hospital_sales(hospital_stats_df, hospital_sales_assignments_df)\n        combined_df = combine_data(compensation_df, hospital_sales_df)\n        selected_df = select_fields(combined_df)\n        growth_df = join_growth_opportunities(logistics_channels_df, growth_opportunities_df)\n        sales_trends_df = join_sales_trends(historical_sales_df, third_party_sales_trends_df)\n        sales_trends_df = calculate_projected_revenue(sales_trends_df)\n        target_years_df = generate_target_years(sales_trends_df)\n        filtered_df = filter_target_years(target_years_df)\n        final_df = join_company_goals(filtered_df, company_goals_df)\n        sorted_df = sort_records(final_df)\n        final_df = define_schema_contract(sorted_df)\n        write_final_output(final_df)\n    except Exception as e:\n        logger.error(f\"An error occurred during the ETL process: {e}\")\n        raise\n\nhandle_exceptions()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}