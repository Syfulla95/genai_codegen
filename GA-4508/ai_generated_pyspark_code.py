"import logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import IntegerType, StringType, DateType, FloatType\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Function to load data from Unity Catalog tables\ndef load_data_from_unity_catalog(table_name):\n    try:\n        logger.info(f\"Loading data from Unity Catalog table: {table_name}\")\n        df = spark.table(table_name)\n        return df\n    except Exception as e:\n        logger.error(f\"Error loading data from {table_name}: {str(e)}\")\n        raise\n\n# Function to perform transformations\ndef transform_data(df, region):\n    try:\n        logger.info(f\"Transforming data for region: {region}\")\n        \n        # Fix Dates\n        df = df.withColumn(\"Order Date\", F.concat_ws(\"-\", F.col(\"Order Year\"), F.col(\"Order Month\"), F.col(\"Order Day\")).cast(DateType())) \\\n               .withColumn(\"Ship Date\", F.concat_ws(\"-\", F.col(\"Ship Year\"), F.col(\"Ship Month\"), F.col(\"Ship Day\")).cast(DateType())) \\\n               .withColumn(\"Region\", F.lit(region)) \\\n               .withColumnRenamed(\"Discounts\", \"Discount\") \\\n               .withColumnRenamed(\"Product\", \"Product Name\") \\\n               .drop(\"Order Year\", \"Order Month\", \"Order Day\", \"Ship Year\", \"Ship Month\", \"Ship Day\")\n        \n        # Remove Nulls\n        df = df.filter(F.col(\"Order ID\").isNotNull())\n        \n        # Fix Data Type\n        df = df.withColumn(\"Discount\", F.col(\"Discount\").cast(StringType())) \\\n               .withColumn(\"Sales\", F.regexp_replace(F.col(\"Sales\"), \"[^0-9.]\", \"\").cast(FloatType()))\n        \n        # Rename States\n        state_abbreviations = {\"California\": \"CA\", \"New York\": \"NY\"}  # Example mapping\n        df = df.replace(state_abbreviations, subset=[\"State\"])\n        \n        return df\n    except Exception as e:\n        logger.error(f\"Error transforming data for region {region}: {str(e)}\")\n        raise\n\n# Function to perform pivoting and unpivoting\ndef pivot_quota_data(df):\n    try:\n        logger.info(\"Pivoting quota data\")\n        df = df.select(\"Region\", F.expr(\"stack(4, '2015', `2015`, '2016', `2016`, '2017', `2017`, '2018', `2018`) as (Year, Quota)\")) \\\n               .withColumn(\"Year\", F.col(\"Year\").cast(IntegerType()))\n        return df\n    except Exception as e:\n        logger.error(f\"Error pivoting quota data: {str(e)}\")\n        raise\n\n# Function to perform joins and custom calculations\ndef join_and_calculate(df_orders, df_returns, df_quota):\n    try:\n        logger.info(\"Joining orders and returns data\")\n        df = df_orders.join(df_returns, [\"Order ID\", \"Product ID\"], \"left\") \\\n                      .withColumn(\"Returned?\", F.when(F.col(\"Return Reason\").isNotNull(), F.lit(\"Yes\")).otherwise(F.lit(\"No\"))) \\\n                      .withColumn(\"Days to Ship\", F.datediff(F.col(\"Ship Date\"), F.col(\"Order Date\"))) \\\n                      .withColumn(\"Discount\", F.coalesce(F.col(\"Discount\"), F.lit(0))) \\\n                      .withColumn(\"Year of Sale\", F.year(F.col(\"Order Date\"))) \\\n                      .filter(~((F.col(\"Discount\") >= 17) & (F.col(\"Discount\") <= 18)))\n        \n        logger.info(\"Joining orders and quota data\")\n        df = df.join(df_quota, [\"Region\", \"Year\"], \"inner\")\n        \n        return df\n    except Exception as e:\n        logger.error(f\"Error joining and calculating data: {str(e)}\")\n        raise\n\n# Function to clean notes and approver fields\ndef clean_notes_and_approver(df):\n    try:\n        logger.info(\"Cleaning notes and approver fields\")\n        df = df.withColumn(\"Return Notes\", F.split(F.col(\"Notes\"), \",\")[0]) \\\n               .withColumn(\"Approver\", F.split(F.col(\"Notes\"), \",\")[1]) \\\n               .drop(\"Notes\") \\\n               .withColumn(\"Approver\", F.trim(F.col(\"Approver\")))\n        return df\n    except Exception as e:\n        logger.error(f\"Error cleaning notes and approver fields: {str(e)}\")\n        raise\n\n# Function to aggregate sales data\ndef aggregate_sales_data(df):\n    try:\n        logger.info(\"Aggregating sales data\")\n        df_agg = df.groupBy(\"Region\", \"Year of Sale\").agg(\n            F.sum(\"Profit\").alias(\"Total Profit\"),\n            F.sum(\"Sales\").alias(\"Total Sales\"),\n            F.sum(\"Quantity\").alias(\"Total Quantity\"),\n            F.avg(\"Discount\").alias(\"Average Discount\")\n        )\n        return df_agg\n    except Exception as e:\n        logger.error(f\"Error aggregating sales data: {str(e)}\")\n        raise\n\n# Load data from Unity Catalog tables\ndf_orders_central = load_data_from_unity_catalog(\"catalog.db.orders_central\")\ndf_orders_west = load_data_from_unity_catalog(\"catalog.db.orders_west\")\ndf_orders_east = load_data_from_unity_catalog(\"catalog.db.orders_east\")\ndf_orders_south = load_data_from_unity_catalog(\"catalog.db.orders_south\")\ndf_returns = load_data_from_unity_catalog(\"catalog.db.returns\")\ndf_quota = load_data_from_unity_catalog(\"catalog.db.quota\")\n\n# Transform data\ndf_orders_central_transformed = transform_data(df_orders_central, \"Central\")\ndf_orders_west_transformed = transform_data(df_orders_west, \"West\")\ndf_orders_east_transformed = transform_data(df_orders_east, \"East\")\ndf_orders_south_transformed = transform_data(df_orders_south, \"South\")\n\n# Union all orders data\ndf_all_orders = df_orders_central_transformed.union(df_orders_west_transformed).union(df_orders_east_transformed).union(df_orders_south_transformed)\n\n# Pivot quota data\ndf_quota_pivoted = pivot_quota_data(df_quota)\n\n# Join and calculate\ndf_joined = join_and_calculate(df_all_orders, df_returns, df_quota_pivoted)\n\n# Clean notes and approver fields\ndf_cleaned = clean_notes_and_approver(df_joined)\n\n# Aggregate sales data\ndf_aggregated_sales = aggregate_sales_data(df_cleaned)\n\n# Write output to Unity Catalog tables\ntry:\n    logger.info(\"Writing aggregated sales data to Unity Catalog\")\n    spark.sql(\"DROP TABLE IF EXISTS catalog.db.annual_regional_performance\")\n    df_aggregated_sales.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.db.annual_regional_performance\")\n    \n    logger.info(\"Writing detailed sales data to Unity Catalog\")\n    spark.sql(\"DROP TABLE IF EXISTS catalog.db.superstore_sales\")\n    df_cleaned.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.db.superstore_sales\")\nexcept Exception as e:\n    logger.error(f\"Error writing data to Unity Catalog: {str(e)}\")\n    raise\n\nlogger.info(\"ETL process completed successfully\")\n"